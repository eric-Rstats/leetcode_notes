{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter04_getting-started-with-neural-networks.i",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eric-Rstats/practice-coding/blob/master/deeplearning_with_keras_version2/chapter4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-kWs-1OuGVu"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4fAHtnuGVw"
      },
      "source": [
        "# Getting started with neural networks: classification and regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztq-vRICuGVx"
      },
      "source": [
        "## Classifying movie reviews: a binary classification example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vearHKuVuGVx"
      },
      "source": [
        "### The IMDB dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgAruU19uGVx"
      },
      "source": [
        "**Loading the IMDB dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUMtQxWYwN5z",
        "outputId": "8ae75f88-9b3e-4757-c6f5-bd112f788b1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "    num_words=10000\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWVzd9D_uGVy",
        "outputId": "770e0cf2-d3c6-48b4-aabd-65ece48a9628"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7rHxG_DuGVz",
        "outputId": "6d65a3f0-07bc-41aa-93c1-3163ae568919"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1lUBTyOuGVz",
        "outputId": "ab10caf3-4f58-46d3-c2d7-c5cfc9d70ac8"
      },
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F0ZHyRouGVz"
      },
      "source": [
        "**Decoding reviews back to text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUTzmGe0uGV0"
      },
      "source": [
        "#\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZminuDzpwp5Y",
        "outputId": "37710014-a7d3-47eb-9dab-272f47046c35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 将序列转化回文本\n",
        "# Note that the indices are offset by 3 because 0, 1, and 2 are reserved indices for “padding,” “start of sequence,” and “unknown.”.\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = \" \".join(\n",
        "    [reverse_word_index.get(i-3, '?') for i in train_data[0]]\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GgjDn4yxh8G",
        "outputId": "9e97a8c6-acd9-46b8-8d25-e30e47af0881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_index"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fawn': 34701,\n",
              " 'tsukino': 52006,\n",
              " 'nunnery': 52007,\n",
              " 'sonja': 16816,\n",
              " 'vani': 63951,\n",
              " 'woods': 1408,\n",
              " 'spiders': 16115,\n",
              " 'hanging': 2345,\n",
              " 'woody': 2289,\n",
              " 'trawling': 52008,\n",
              " \"hold's\": 52009,\n",
              " 'comically': 11307,\n",
              " 'localized': 40830,\n",
              " 'disobeying': 30568,\n",
              " \"'royale\": 52010,\n",
              " \"harpo's\": 40831,\n",
              " 'canet': 52011,\n",
              " 'aileen': 19313,\n",
              " 'acurately': 52012,\n",
              " \"diplomat's\": 52013,\n",
              " 'rickman': 25242,\n",
              " 'arranged': 6746,\n",
              " 'rumbustious': 52014,\n",
              " 'familiarness': 52015,\n",
              " \"spider'\": 52016,\n",
              " 'hahahah': 68804,\n",
              " \"wood'\": 52017,\n",
              " 'transvestism': 40833,\n",
              " \"hangin'\": 34702,\n",
              " 'bringing': 2338,\n",
              " 'seamier': 40834,\n",
              " 'wooded': 34703,\n",
              " 'bravora': 52018,\n",
              " 'grueling': 16817,\n",
              " 'wooden': 1636,\n",
              " 'wednesday': 16818,\n",
              " \"'prix\": 52019,\n",
              " 'altagracia': 34704,\n",
              " 'circuitry': 52020,\n",
              " 'crotch': 11585,\n",
              " 'busybody': 57766,\n",
              " \"tart'n'tangy\": 52021,\n",
              " 'burgade': 14129,\n",
              " 'thrace': 52023,\n",
              " \"tom's\": 11038,\n",
              " 'snuggles': 52025,\n",
              " 'francesco': 29114,\n",
              " 'complainers': 52027,\n",
              " 'templarios': 52125,\n",
              " '272': 40835,\n",
              " '273': 52028,\n",
              " 'zaniacs': 52130,\n",
              " '275': 34706,\n",
              " 'consenting': 27631,\n",
              " 'snuggled': 40836,\n",
              " 'inanimate': 15492,\n",
              " 'uality': 52030,\n",
              " 'bronte': 11926,\n",
              " 'errors': 4010,\n",
              " 'dialogs': 3230,\n",
              " \"yomada's\": 52031,\n",
              " \"madman's\": 34707,\n",
              " 'dialoge': 30585,\n",
              " 'usenet': 52033,\n",
              " 'videodrome': 40837,\n",
              " \"kid'\": 26338,\n",
              " 'pawed': 52034,\n",
              " \"'girlfriend'\": 30569,\n",
              " \"'pleasure\": 52035,\n",
              " \"'reloaded'\": 52036,\n",
              " \"kazakos'\": 40839,\n",
              " 'rocque': 52037,\n",
              " 'mailings': 52038,\n",
              " 'brainwashed': 11927,\n",
              " 'mcanally': 16819,\n",
              " \"tom''\": 52039,\n",
              " 'kurupt': 25243,\n",
              " 'affiliated': 21905,\n",
              " 'babaganoosh': 52040,\n",
              " \"noe's\": 40840,\n",
              " 'quart': 40841,\n",
              " 'kids': 359,\n",
              " 'uplifting': 5034,\n",
              " 'controversy': 7093,\n",
              " 'kida': 21906,\n",
              " 'kidd': 23379,\n",
              " \"error'\": 52041,\n",
              " 'neurologist': 52042,\n",
              " 'spotty': 18510,\n",
              " 'cobblers': 30570,\n",
              " 'projection': 9878,\n",
              " 'fastforwarding': 40842,\n",
              " 'sters': 52043,\n",
              " \"eggar's\": 52044,\n",
              " 'etherything': 52045,\n",
              " 'gateshead': 40843,\n",
              " 'airball': 34708,\n",
              " 'unsinkable': 25244,\n",
              " 'stern': 7180,\n",
              " \"cervi's\": 52046,\n",
              " 'dnd': 40844,\n",
              " 'dna': 11586,\n",
              " 'insecurity': 20598,\n",
              " \"'reboot'\": 52047,\n",
              " 'trelkovsky': 11037,\n",
              " 'jaekel': 52048,\n",
              " 'sidebars': 52049,\n",
              " \"sforza's\": 52050,\n",
              " 'distortions': 17633,\n",
              " 'mutinies': 52051,\n",
              " 'sermons': 30602,\n",
              " '7ft': 40846,\n",
              " 'boobage': 52052,\n",
              " \"o'bannon's\": 52053,\n",
              " 'populations': 23380,\n",
              " 'chulak': 52054,\n",
              " 'mesmerize': 27633,\n",
              " 'quinnell': 52055,\n",
              " 'yahoo': 10307,\n",
              " 'meteorologist': 52057,\n",
              " 'beswick': 42577,\n",
              " 'boorman': 15493,\n",
              " 'voicework': 40847,\n",
              " \"ster'\": 52058,\n",
              " 'blustering': 22922,\n",
              " 'hj': 52059,\n",
              " 'intake': 27634,\n",
              " 'morally': 5621,\n",
              " 'jumbling': 40849,\n",
              " 'bowersock': 52060,\n",
              " \"'porky's'\": 52061,\n",
              " 'gershon': 16821,\n",
              " 'ludicrosity': 40850,\n",
              " 'coprophilia': 52062,\n",
              " 'expressively': 40851,\n",
              " \"india's\": 19500,\n",
              " \"post's\": 34710,\n",
              " 'wana': 52063,\n",
              " 'wang': 5283,\n",
              " 'wand': 30571,\n",
              " 'wane': 25245,\n",
              " 'edgeways': 52321,\n",
              " 'titanium': 34711,\n",
              " 'pinta': 40852,\n",
              " 'want': 178,\n",
              " 'pinto': 30572,\n",
              " 'whoopdedoodles': 52065,\n",
              " 'tchaikovsky': 21908,\n",
              " 'travel': 2103,\n",
              " \"'victory'\": 52066,\n",
              " 'copious': 11928,\n",
              " 'gouge': 22433,\n",
              " \"chapters'\": 52067,\n",
              " 'barbra': 6702,\n",
              " 'uselessness': 30573,\n",
              " \"wan'\": 52068,\n",
              " 'assimilated': 27635,\n",
              " 'petiot': 16116,\n",
              " 'most\\x85and': 52069,\n",
              " 'dinosaurs': 3930,\n",
              " 'wrong': 352,\n",
              " 'seda': 52070,\n",
              " 'stollen': 52071,\n",
              " 'sentencing': 34712,\n",
              " 'ouroboros': 40853,\n",
              " 'assimilates': 40854,\n",
              " 'colorfully': 40855,\n",
              " 'glenne': 27636,\n",
              " 'dongen': 52072,\n",
              " 'subplots': 4760,\n",
              " 'kiloton': 52073,\n",
              " 'chandon': 23381,\n",
              " \"effect'\": 34713,\n",
              " 'snugly': 27637,\n",
              " 'kuei': 40856,\n",
              " 'welcomed': 9092,\n",
              " 'dishonor': 30071,\n",
              " 'concurrence': 52075,\n",
              " 'stoicism': 23382,\n",
              " \"guys'\": 14896,\n",
              " \"beroemd'\": 52077,\n",
              " 'butcher': 6703,\n",
              " \"melfi's\": 40857,\n",
              " 'aargh': 30623,\n",
              " 'playhouse': 20599,\n",
              " 'wickedly': 11308,\n",
              " 'fit': 1180,\n",
              " 'labratory': 52078,\n",
              " 'lifeline': 40859,\n",
              " 'screaming': 1927,\n",
              " 'fix': 4287,\n",
              " 'cineliterate': 52079,\n",
              " 'fic': 52080,\n",
              " 'fia': 52081,\n",
              " 'fig': 34714,\n",
              " 'fmvs': 52082,\n",
              " 'fie': 52083,\n",
              " 'reentered': 52084,\n",
              " 'fin': 30574,\n",
              " 'doctresses': 52085,\n",
              " 'fil': 52086,\n",
              " 'zucker': 12606,\n",
              " 'ached': 31931,\n",
              " 'counsil': 52088,\n",
              " 'paterfamilias': 52089,\n",
              " 'songwriter': 13885,\n",
              " 'shivam': 34715,\n",
              " 'hurting': 9654,\n",
              " 'effects': 299,\n",
              " 'slauther': 52090,\n",
              " \"'flame'\": 52091,\n",
              " 'sommerset': 52092,\n",
              " 'interwhined': 52093,\n",
              " 'whacking': 27638,\n",
              " 'bartok': 52094,\n",
              " 'barton': 8775,\n",
              " 'frewer': 21909,\n",
              " \"fi'\": 52095,\n",
              " 'ingrid': 6192,\n",
              " 'stribor': 30575,\n",
              " 'approporiately': 52096,\n",
              " 'wobblyhand': 52097,\n",
              " 'tantalisingly': 52098,\n",
              " 'ankylosaurus': 52099,\n",
              " 'parasites': 17634,\n",
              " 'childen': 52100,\n",
              " \"jenkins'\": 52101,\n",
              " 'metafiction': 52102,\n",
              " 'golem': 17635,\n",
              " 'indiscretion': 40860,\n",
              " \"reeves'\": 23383,\n",
              " \"inamorata's\": 57781,\n",
              " 'brittannica': 52104,\n",
              " 'adapt': 7916,\n",
              " \"russo's\": 30576,\n",
              " 'guitarists': 48246,\n",
              " 'abbott': 10553,\n",
              " 'abbots': 40861,\n",
              " 'lanisha': 17649,\n",
              " 'magickal': 40863,\n",
              " 'mattter': 52105,\n",
              " \"'willy\": 52106,\n",
              " 'pumpkins': 34716,\n",
              " 'stuntpeople': 52107,\n",
              " 'estimate': 30577,\n",
              " 'ugghhh': 40864,\n",
              " 'gameplay': 11309,\n",
              " \"wern't\": 52108,\n",
              " \"n'sync\": 40865,\n",
              " 'sickeningly': 16117,\n",
              " 'chiara': 40866,\n",
              " 'disturbed': 4011,\n",
              " 'portmanteau': 40867,\n",
              " 'ineffectively': 52109,\n",
              " \"duchonvey's\": 82143,\n",
              " \"nasty'\": 37519,\n",
              " 'purpose': 1285,\n",
              " 'lazers': 52112,\n",
              " 'lightened': 28105,\n",
              " 'kaliganj': 52113,\n",
              " 'popularism': 52114,\n",
              " \"damme's\": 18511,\n",
              " 'stylistics': 30578,\n",
              " 'mindgaming': 52115,\n",
              " 'spoilerish': 46449,\n",
              " \"'corny'\": 52117,\n",
              " 'boerner': 34718,\n",
              " 'olds': 6792,\n",
              " 'bakelite': 52118,\n",
              " 'renovated': 27639,\n",
              " 'forrester': 27640,\n",
              " \"lumiere's\": 52119,\n",
              " 'gaskets': 52024,\n",
              " 'needed': 884,\n",
              " 'smight': 34719,\n",
              " 'master': 1297,\n",
              " \"edie's\": 25905,\n",
              " 'seeber': 40868,\n",
              " 'hiya': 52120,\n",
              " 'fuzziness': 52121,\n",
              " 'genesis': 14897,\n",
              " 'rewards': 12607,\n",
              " 'enthrall': 30579,\n",
              " \"'about\": 40869,\n",
              " \"recollection's\": 52122,\n",
              " 'mutilated': 11039,\n",
              " 'fatherlands': 52123,\n",
              " \"fischer's\": 52124,\n",
              " 'positively': 5399,\n",
              " '270': 34705,\n",
              " 'ahmed': 34720,\n",
              " 'zatoichi': 9836,\n",
              " 'bannister': 13886,\n",
              " 'anniversaries': 52127,\n",
              " \"helm's\": 30580,\n",
              " \"'work'\": 52128,\n",
              " 'exclaimed': 34721,\n",
              " \"'unfunny'\": 52129,\n",
              " '274': 52029,\n",
              " 'feeling': 544,\n",
              " \"wanda's\": 52131,\n",
              " 'dolan': 33266,\n",
              " '278': 52133,\n",
              " 'peacoat': 52134,\n",
              " 'brawny': 40870,\n",
              " 'mishra': 40871,\n",
              " 'worlders': 40872,\n",
              " 'protags': 52135,\n",
              " 'skullcap': 52136,\n",
              " 'dastagir': 57596,\n",
              " 'affairs': 5622,\n",
              " 'wholesome': 7799,\n",
              " 'hymen': 52137,\n",
              " 'paramedics': 25246,\n",
              " 'unpersons': 52138,\n",
              " 'heavyarms': 52139,\n",
              " 'affaire': 52140,\n",
              " 'coulisses': 52141,\n",
              " 'hymer': 40873,\n",
              " 'kremlin': 52142,\n",
              " 'shipments': 30581,\n",
              " 'pixilated': 52143,\n",
              " \"'00s\": 30582,\n",
              " 'diminishing': 18512,\n",
              " 'cinematic': 1357,\n",
              " 'resonates': 14898,\n",
              " 'simplify': 40874,\n",
              " \"nature'\": 40875,\n",
              " 'temptresses': 40876,\n",
              " 'reverence': 16822,\n",
              " 'resonated': 19502,\n",
              " 'dailey': 34722,\n",
              " '2\\x85': 52144,\n",
              " 'treize': 27641,\n",
              " 'majo': 52145,\n",
              " 'kiya': 21910,\n",
              " 'woolnough': 52146,\n",
              " 'thanatos': 39797,\n",
              " 'sandoval': 35731,\n",
              " 'dorama': 40879,\n",
              " \"o'shaughnessy\": 52147,\n",
              " 'tech': 4988,\n",
              " 'fugitives': 32018,\n",
              " 'teck': 30583,\n",
              " \"'e'\": 76125,\n",
              " 'doesn’t': 40881,\n",
              " 'purged': 52149,\n",
              " 'saying': 657,\n",
              " \"martians'\": 41095,\n",
              " 'norliss': 23418,\n",
              " 'dickey': 27642,\n",
              " 'dicker': 52152,\n",
              " \"'sependipity\": 52153,\n",
              " 'padded': 8422,\n",
              " 'ordell': 57792,\n",
              " \"sturges'\": 40882,\n",
              " 'independentcritics': 52154,\n",
              " 'tempted': 5745,\n",
              " \"atkinson's\": 34724,\n",
              " 'hounded': 25247,\n",
              " 'apace': 52155,\n",
              " 'clicked': 15494,\n",
              " \"'humor'\": 30584,\n",
              " \"martino's\": 17177,\n",
              " \"'supporting\": 52156,\n",
              " 'warmongering': 52032,\n",
              " \"zemeckis's\": 34725,\n",
              " 'lube': 21911,\n",
              " 'shocky': 52157,\n",
              " 'plate': 7476,\n",
              " 'plata': 40883,\n",
              " 'sturgess': 40884,\n",
              " \"nerds'\": 40885,\n",
              " 'plato': 20600,\n",
              " 'plath': 34726,\n",
              " 'platt': 40886,\n",
              " 'mcnab': 52159,\n",
              " 'clumsiness': 27643,\n",
              " 'altogether': 3899,\n",
              " 'massacring': 42584,\n",
              " 'bicenntinial': 52160,\n",
              " 'skaal': 40887,\n",
              " 'droning': 14360,\n",
              " 'lds': 8776,\n",
              " 'jaguar': 21912,\n",
              " \"cale's\": 34727,\n",
              " 'nicely': 1777,\n",
              " 'mummy': 4588,\n",
              " \"lot's\": 18513,\n",
              " 'patch': 10086,\n",
              " 'kerkhof': 50202,\n",
              " \"leader's\": 52161,\n",
              " \"'movie\": 27644,\n",
              " 'uncomfirmed': 52162,\n",
              " 'heirloom': 40888,\n",
              " 'wrangle': 47360,\n",
              " 'emotion\\x85': 52163,\n",
              " \"'stargate'\": 52164,\n",
              " 'pinoy': 40889,\n",
              " 'conchatta': 40890,\n",
              " 'broeke': 41128,\n",
              " 'advisedly': 40891,\n",
              " \"barker's\": 17636,\n",
              " 'descours': 52166,\n",
              " 'lots': 772,\n",
              " 'lotr': 9259,\n",
              " 'irs': 9879,\n",
              " 'lott': 52167,\n",
              " 'xvi': 40892,\n",
              " 'irk': 34728,\n",
              " 'irl': 52168,\n",
              " 'ira': 6887,\n",
              " 'belzer': 21913,\n",
              " 'irc': 52169,\n",
              " 'ire': 27645,\n",
              " 'requisites': 40893,\n",
              " 'discipline': 7693,\n",
              " 'lyoko': 52961,\n",
              " 'extend': 11310,\n",
              " 'nature': 873,\n",
              " \"'dickie'\": 52170,\n",
              " 'optimist': 40894,\n",
              " 'lapping': 30586,\n",
              " 'superficial': 3900,\n",
              " 'vestment': 52171,\n",
              " 'extent': 2823,\n",
              " 'tendons': 52172,\n",
              " \"heller's\": 52173,\n",
              " 'quagmires': 52174,\n",
              " 'miyako': 52175,\n",
              " 'moocow': 20601,\n",
              " \"coles'\": 52176,\n",
              " 'lookit': 40895,\n",
              " 'ravenously': 52177,\n",
              " 'levitating': 40896,\n",
              " 'perfunctorily': 52178,\n",
              " 'lookin': 30587,\n",
              " \"lot'\": 40898,\n",
              " 'lookie': 52179,\n",
              " 'fearlessly': 34870,\n",
              " 'libyan': 52181,\n",
              " 'fondles': 40899,\n",
              " 'gopher': 35714,\n",
              " 'wearying': 40901,\n",
              " \"nz's\": 52182,\n",
              " 'minuses': 27646,\n",
              " 'puposelessly': 52183,\n",
              " 'shandling': 52184,\n",
              " 'decapitates': 31268,\n",
              " 'humming': 11929,\n",
              " \"'nother\": 40902,\n",
              " 'smackdown': 21914,\n",
              " 'underdone': 30588,\n",
              " 'frf': 40903,\n",
              " 'triviality': 52185,\n",
              " 'fro': 25248,\n",
              " 'bothers': 8777,\n",
              " \"'kensington\": 52186,\n",
              " 'much': 73,\n",
              " 'muco': 34730,\n",
              " 'wiseguy': 22615,\n",
              " \"richie's\": 27648,\n",
              " 'tonino': 40904,\n",
              " 'unleavened': 52187,\n",
              " 'fry': 11587,\n",
              " \"'tv'\": 40905,\n",
              " 'toning': 40906,\n",
              " 'obese': 14361,\n",
              " 'sensationalized': 30589,\n",
              " 'spiv': 40907,\n",
              " 'spit': 6259,\n",
              " 'arkin': 7364,\n",
              " 'charleton': 21915,\n",
              " 'jeon': 16823,\n",
              " 'boardroom': 21916,\n",
              " 'doubts': 4989,\n",
              " 'spin': 3084,\n",
              " 'hepo': 53083,\n",
              " 'wildcat': 27649,\n",
              " 'venoms': 10584,\n",
              " 'misconstrues': 52191,\n",
              " 'mesmerising': 18514,\n",
              " 'misconstrued': 40908,\n",
              " 'rescinds': 52192,\n",
              " 'prostrate': 52193,\n",
              " 'majid': 40909,\n",
              " 'climbed': 16479,\n",
              " 'canoeing': 34731,\n",
              " 'majin': 52195,\n",
              " 'animie': 57804,\n",
              " 'sylke': 40910,\n",
              " 'conditioned': 14899,\n",
              " 'waddell': 40911,\n",
              " '3\\x85': 52196,\n",
              " 'hyperdrive': 41188,\n",
              " 'conditioner': 34732,\n",
              " 'bricklayer': 53153,\n",
              " 'hong': 2576,\n",
              " 'memoriam': 52198,\n",
              " 'inventively': 30592,\n",
              " \"levant's\": 25249,\n",
              " 'portobello': 20638,\n",
              " 'remand': 52200,\n",
              " 'mummified': 19504,\n",
              " 'honk': 27650,\n",
              " 'spews': 19505,\n",
              " 'visitations': 40912,\n",
              " 'mummifies': 52201,\n",
              " 'cavanaugh': 25250,\n",
              " 'zeon': 23385,\n",
              " \"jungle's\": 40913,\n",
              " 'viertel': 34733,\n",
              " 'frenchmen': 27651,\n",
              " 'torpedoes': 52202,\n",
              " 'schlessinger': 52203,\n",
              " 'torpedoed': 34734,\n",
              " 'blister': 69876,\n",
              " 'cinefest': 52204,\n",
              " 'furlough': 34735,\n",
              " 'mainsequence': 52205,\n",
              " 'mentors': 40914,\n",
              " 'academic': 9094,\n",
              " 'stillness': 20602,\n",
              " 'academia': 40915,\n",
              " 'lonelier': 52206,\n",
              " 'nibby': 52207,\n",
              " \"losers'\": 52208,\n",
              " 'cineastes': 40916,\n",
              " 'corporate': 4449,\n",
              " 'massaging': 40917,\n",
              " 'bellow': 30593,\n",
              " 'absurdities': 19506,\n",
              " 'expetations': 53241,\n",
              " 'nyfiken': 40918,\n",
              " 'mehras': 75638,\n",
              " 'lasse': 52209,\n",
              " 'visability': 52210,\n",
              " 'militarily': 33946,\n",
              " \"elder'\": 52211,\n",
              " 'gainsbourg': 19023,\n",
              " 'hah': 20603,\n",
              " 'hai': 13420,\n",
              " 'haj': 34736,\n",
              " 'hak': 25251,\n",
              " 'hal': 4311,\n",
              " 'ham': 4892,\n",
              " 'duffer': 53259,\n",
              " 'haa': 52213,\n",
              " 'had': 66,\n",
              " 'advancement': 11930,\n",
              " 'hag': 16825,\n",
              " \"hand'\": 25252,\n",
              " 'hay': 13421,\n",
              " 'mcnamara': 20604,\n",
              " \"mozart's\": 52214,\n",
              " 'duffel': 30731,\n",
              " 'haq': 30594,\n",
              " 'har': 13887,\n",
              " 'has': 44,\n",
              " 'hat': 2401,\n",
              " 'hav': 40919,\n",
              " 'haw': 30595,\n",
              " 'figtings': 52215,\n",
              " 'elders': 15495,\n",
              " 'underpanted': 52216,\n",
              " 'pninson': 52217,\n",
              " 'unequivocally': 27652,\n",
              " \"barbara's\": 23673,\n",
              " \"bello'\": 52219,\n",
              " 'indicative': 12997,\n",
              " 'yawnfest': 40920,\n",
              " 'hexploitation': 52220,\n",
              " \"loder's\": 52221,\n",
              " 'sleuthing': 27653,\n",
              " \"justin's\": 32622,\n",
              " \"'ball\": 52222,\n",
              " \"'summer\": 52223,\n",
              " \"'demons'\": 34935,\n",
              " \"mormon's\": 52225,\n",
              " \"laughton's\": 34737,\n",
              " 'debell': 52226,\n",
              " 'shipyard': 39724,\n",
              " 'unabashedly': 30597,\n",
              " 'disks': 40401,\n",
              " 'crowd': 2290,\n",
              " 'crowe': 10087,\n",
              " \"vancouver's\": 56434,\n",
              " 'mosques': 34738,\n",
              " 'crown': 6627,\n",
              " 'culpas': 52227,\n",
              " 'crows': 27654,\n",
              " 'surrell': 53344,\n",
              " 'flowless': 52229,\n",
              " 'sheirk': 52230,\n",
              " \"'three\": 40923,\n",
              " \"peterson'\": 52231,\n",
              " 'ooverall': 52232,\n",
              " 'perchance': 40924,\n",
              " 'bottom': 1321,\n",
              " 'chabert': 53363,\n",
              " 'sneha': 52233,\n",
              " 'inhuman': 13888,\n",
              " 'ichii': 52234,\n",
              " 'ursla': 52235,\n",
              " 'completly': 30598,\n",
              " 'moviedom': 40925,\n",
              " 'raddick': 52236,\n",
              " 'brundage': 51995,\n",
              " 'brigades': 40926,\n",
              " 'starring': 1181,\n",
              " \"'goal'\": 52237,\n",
              " 'caskets': 52238,\n",
              " 'willcock': 52239,\n",
              " \"threesome's\": 52240,\n",
              " \"mosque'\": 52241,\n",
              " \"cover's\": 52242,\n",
              " 'spaceships': 17637,\n",
              " 'anomalous': 40927,\n",
              " 'ptsd': 27655,\n",
              " 'shirdan': 52243,\n",
              " 'obscenity': 21962,\n",
              " 'lemmings': 30599,\n",
              " 'duccio': 30600,\n",
              " \"levene's\": 52244,\n",
              " \"'gorby'\": 52245,\n",
              " \"teenager's\": 25255,\n",
              " 'marshall': 5340,\n",
              " 'honeymoon': 9095,\n",
              " 'shoots': 3231,\n",
              " 'despised': 12258,\n",
              " 'okabasho': 52246,\n",
              " 'fabric': 8289,\n",
              " 'cannavale': 18515,\n",
              " 'raped': 3537,\n",
              " \"tutt's\": 52247,\n",
              " 'grasping': 17638,\n",
              " 'despises': 18516,\n",
              " \"thief's\": 40928,\n",
              " 'rapes': 8926,\n",
              " 'raper': 52248,\n",
              " \"eyre'\": 27656,\n",
              " 'walchek': 52249,\n",
              " \"elmo's\": 23386,\n",
              " 'perfumes': 40929,\n",
              " 'spurting': 21918,\n",
              " \"exposition'\\x85\": 52250,\n",
              " 'denoting': 52251,\n",
              " 'thesaurus': 34740,\n",
              " \"shoot'\": 40930,\n",
              " 'bonejack': 49759,\n",
              " 'simpsonian': 52253,\n",
              " 'hebetude': 30601,\n",
              " \"hallow's\": 34741,\n",
              " 'desperation\\x85': 52254,\n",
              " 'incinerator': 34742,\n",
              " 'congratulations': 10308,\n",
              " 'humbled': 52255,\n",
              " \"else's\": 5924,\n",
              " 'trelkovski': 40845,\n",
              " \"rape'\": 52256,\n",
              " \"'chapters'\": 59386,\n",
              " '1600s': 52257,\n",
              " 'martian': 7253,\n",
              " 'nicest': 25256,\n",
              " 'eyred': 52259,\n",
              " 'passenger': 9457,\n",
              " 'disgrace': 6041,\n",
              " 'moderne': 52260,\n",
              " 'barrymore': 5120,\n",
              " 'yankovich': 52261,\n",
              " 'moderns': 40931,\n",
              " 'studliest': 52262,\n",
              " 'bedsheet': 52263,\n",
              " 'decapitation': 14900,\n",
              " 'slurring': 52264,\n",
              " \"'nunsploitation'\": 52265,\n",
              " \"'character'\": 34743,\n",
              " 'cambodia': 9880,\n",
              " 'rebelious': 52266,\n",
              " 'pasadena': 27657,\n",
              " 'crowne': 40932,\n",
              " \"'bedchamber\": 52267,\n",
              " 'conjectural': 52268,\n",
              " 'appologize': 52269,\n",
              " 'halfassing': 52270,\n",
              " 'paycheque': 57816,\n",
              " 'palms': 20606,\n",
              " \"'islands\": 52271,\n",
              " 'hawked': 40933,\n",
              " 'palme': 21919,\n",
              " 'conservatively': 40934,\n",
              " 'larp': 64007,\n",
              " 'palma': 5558,\n",
              " 'smelling': 21920,\n",
              " 'aragorn': 12998,\n",
              " 'hawker': 52272,\n",
              " 'hawkes': 52273,\n",
              " 'explosions': 3975,\n",
              " 'loren': 8059,\n",
              " \"pyle's\": 52274,\n",
              " 'shootout': 6704,\n",
              " \"mike's\": 18517,\n",
              " \"driscoll's\": 52275,\n",
              " 'cogsworth': 40935,\n",
              " \"britian's\": 52276,\n",
              " 'childs': 34744,\n",
              " \"portrait's\": 52277,\n",
              " 'chain': 3626,\n",
              " 'whoever': 2497,\n",
              " 'puttered': 52278,\n",
              " 'childe': 52279,\n",
              " 'maywether': 52280,\n",
              " 'chair': 3036,\n",
              " \"rance's\": 52281,\n",
              " 'machu': 34745,\n",
              " 'ballet': 4517,\n",
              " 'grapples': 34746,\n",
              " 'summerize': 76152,\n",
              " 'freelance': 30603,\n",
              " \"andrea's\": 52283,\n",
              " '\\x91very': 52284,\n",
              " 'coolidge': 45879,\n",
              " 'mache': 18518,\n",
              " 'balled': 52285,\n",
              " 'grappled': 40937,\n",
              " 'macha': 18519,\n",
              " 'underlining': 21921,\n",
              " 'macho': 5623,\n",
              " 'oversight': 19507,\n",
              " 'machi': 25257,\n",
              " 'verbally': 11311,\n",
              " 'tenacious': 21922,\n",
              " 'windshields': 40938,\n",
              " 'paychecks': 18557,\n",
              " 'jerk': 3396,\n",
              " \"good'\": 11931,\n",
              " 'prancer': 34748,\n",
              " 'prances': 21923,\n",
              " 'olympus': 52286,\n",
              " 'lark': 21924,\n",
              " 'embark': 10785,\n",
              " 'gloomy': 7365,\n",
              " 'jehaan': 52287,\n",
              " 'turaqui': 52288,\n",
              " \"child'\": 20607,\n",
              " 'locked': 2894,\n",
              " 'pranced': 52289,\n",
              " 'exact': 2588,\n",
              " 'unattuned': 52290,\n",
              " 'minute': 783,\n",
              " 'skewed': 16118,\n",
              " 'hodgins': 40940,\n",
              " 'skewer': 34749,\n",
              " 'think\\x85': 52291,\n",
              " 'rosenstein': 38765,\n",
              " 'helmit': 52292,\n",
              " 'wrestlemanias': 34750,\n",
              " 'hindered': 16826,\n",
              " \"martha's\": 30604,\n",
              " 'cheree': 52293,\n",
              " \"pluckin'\": 52294,\n",
              " 'ogles': 40941,\n",
              " 'heavyweight': 11932,\n",
              " 'aada': 82190,\n",
              " 'chopping': 11312,\n",
              " 'strongboy': 61534,\n",
              " 'hegemonic': 41342,\n",
              " 'adorns': 40942,\n",
              " 'xxth': 41346,\n",
              " 'nobuhiro': 34751,\n",
              " 'capitães': 52298,\n",
              " 'kavogianni': 52299,\n",
              " 'antwerp': 13422,\n",
              " 'celebrated': 6538,\n",
              " 'roarke': 52300,\n",
              " 'baggins': 40943,\n",
              " 'cheeseburgers': 31270,\n",
              " 'matras': 52301,\n",
              " \"nineties'\": 52302,\n",
              " \"'craig'\": 52303,\n",
              " 'celebrates': 12999,\n",
              " 'unintentionally': 3383,\n",
              " 'drafted': 14362,\n",
              " 'climby': 52304,\n",
              " '303': 52305,\n",
              " 'oldies': 18520,\n",
              " 'climbs': 9096,\n",
              " 'honour': 9655,\n",
              " 'plucking': 34752,\n",
              " '305': 30074,\n",
              " 'address': 5514,\n",
              " 'menjou': 40944,\n",
              " \"'freak'\": 42592,\n",
              " 'dwindling': 19508,\n",
              " 'benson': 9458,\n",
              " 'white’s': 52307,\n",
              " 'shamelessness': 40945,\n",
              " 'impacted': 21925,\n",
              " 'upatz': 52308,\n",
              " 'cusack': 3840,\n",
              " \"flavia's\": 37567,\n",
              " 'effette': 52309,\n",
              " 'influx': 34753,\n",
              " 'boooooooo': 52310,\n",
              " 'dimitrova': 52311,\n",
              " 'houseman': 13423,\n",
              " 'bigas': 25259,\n",
              " 'boylen': 52312,\n",
              " 'phillipenes': 52313,\n",
              " 'fakery': 40946,\n",
              " \"grandpa's\": 27658,\n",
              " 'darnell': 27659,\n",
              " 'undergone': 19509,\n",
              " 'handbags': 52315,\n",
              " 'perished': 21926,\n",
              " 'pooped': 37778,\n",
              " 'vigour': 27660,\n",
              " 'opposed': 3627,\n",
              " 'etude': 52316,\n",
              " \"caine's\": 11799,\n",
              " 'doozers': 52317,\n",
              " 'photojournals': 34754,\n",
              " 'perishes': 52318,\n",
              " 'constrains': 34755,\n",
              " 'migenes': 40948,\n",
              " 'consoled': 30605,\n",
              " 'alastair': 16827,\n",
              " 'wvs': 52319,\n",
              " 'ooooooh': 52320,\n",
              " 'approving': 34756,\n",
              " 'consoles': 40949,\n",
              " 'disparagement': 52064,\n",
              " 'futureistic': 52322,\n",
              " 'rebounding': 52323,\n",
              " \"'date\": 52324,\n",
              " 'gregoire': 52325,\n",
              " 'rutherford': 21927,\n",
              " 'americanised': 34757,\n",
              " 'novikov': 82196,\n",
              " 'following': 1042,\n",
              " 'munroe': 34758,\n",
              " \"morita'\": 52326,\n",
              " 'christenssen': 52327,\n",
              " 'oatmeal': 23106,\n",
              " 'fossey': 25260,\n",
              " 'livered': 40950,\n",
              " 'listens': 13000,\n",
              " \"'marci\": 76164,\n",
              " \"otis's\": 52330,\n",
              " 'thanking': 23387,\n",
              " 'maude': 16019,\n",
              " 'extensions': 34759,\n",
              " 'ameteurish': 52332,\n",
              " \"commender's\": 52333,\n",
              " 'agricultural': 27661,\n",
              " 'convincingly': 4518,\n",
              " 'fueled': 17639,\n",
              " 'mahattan': 54014,\n",
              " \"paris's\": 40952,\n",
              " 'vulkan': 52336,\n",
              " 'stapes': 52337,\n",
              " 'odysessy': 52338,\n",
              " 'harmon': 12259,\n",
              " 'surfing': 4252,\n",
              " 'halloran': 23494,\n",
              " 'unbelieveably': 49580,\n",
              " \"'offed'\": 52339,\n",
              " 'quadrant': 30607,\n",
              " 'inhabiting': 19510,\n",
              " 'nebbish': 34760,\n",
              " 'forebears': 40953,\n",
              " 'skirmish': 34761,\n",
              " 'ocassionally': 52340,\n",
              " \"'resist\": 52341,\n",
              " 'impactful': 21928,\n",
              " 'spicier': 52342,\n",
              " 'touristy': 40954,\n",
              " \"'football'\": 52343,\n",
              " 'webpage': 40955,\n",
              " 'exurbia': 52345,\n",
              " 'jucier': 52346,\n",
              " 'professors': 14901,\n",
              " 'structuring': 34762,\n",
              " 'jig': 30608,\n",
              " 'overlord': 40956,\n",
              " 'disconnect': 25261,\n",
              " 'sniffle': 82201,\n",
              " 'slimeball': 40957,\n",
              " 'jia': 40958,\n",
              " 'milked': 16828,\n",
              " 'banjoes': 40959,\n",
              " 'jim': 1237,\n",
              " 'workforces': 52348,\n",
              " 'jip': 52349,\n",
              " 'rotweiller': 52350,\n",
              " 'mundaneness': 34763,\n",
              " \"'ninja'\": 52351,\n",
              " \"dead'\": 11040,\n",
              " \"cipriani's\": 40960,\n",
              " 'modestly': 20608,\n",
              " \"professor'\": 52352,\n",
              " 'shacked': 40961,\n",
              " 'bashful': 34764,\n",
              " 'sorter': 23388,\n",
              " 'overpowering': 16120,\n",
              " 'workmanlike': 18521,\n",
              " 'henpecked': 27662,\n",
              " 'sorted': 18522,\n",
              " \"jōb's\": 52354,\n",
              " \"'always\": 52355,\n",
              " \"'baptists\": 34765,\n",
              " 'dreamcatchers': 52356,\n",
              " \"'silence'\": 52357,\n",
              " 'hickory': 21929,\n",
              " 'fun\\x97yet': 52358,\n",
              " 'breakumentary': 52359,\n",
              " 'didn': 15496,\n",
              " 'didi': 52360,\n",
              " 'pealing': 52361,\n",
              " 'dispite': 40962,\n",
              " \"italy's\": 25262,\n",
              " 'instability': 21930,\n",
              " 'quarter': 6539,\n",
              " 'quartet': 12608,\n",
              " 'padmé': 52362,\n",
              " \"'bleedmedry\": 52363,\n",
              " 'pahalniuk': 52364,\n",
              " 'honduras': 52365,\n",
              " 'bursting': 10786,\n",
              " \"pablo's\": 41465,\n",
              " 'irremediably': 52367,\n",
              " 'presages': 40963,\n",
              " 'bowlegged': 57832,\n",
              " 'dalip': 65183,\n",
              " 'entering': 6260,\n",
              " 'newsradio': 76172,\n",
              " 'presaged': 54150,\n",
              " \"giallo's\": 27663,\n",
              " 'bouyant': 40964,\n",
              " 'amerterish': 52368,\n",
              " 'rajni': 18523,\n",
              " 'leeves': 30610,\n",
              " 'macauley': 34767,\n",
              " 'seriously': 612,\n",
              " 'sugercoma': 52369,\n",
              " 'grimstead': 52370,\n",
              " \"'fairy'\": 52371,\n",
              " 'zenda': 30611,\n",
              " \"'twins'\": 52372,\n",
              " 'realisation': 17640,\n",
              " 'highsmith': 27664,\n",
              " 'raunchy': 7817,\n",
              " 'incentives': 40965,\n",
              " 'flatson': 52374,\n",
              " 'snooker': 35097,\n",
              " 'crazies': 16829,\n",
              " 'crazier': 14902,\n",
              " 'grandma': 7094,\n",
              " 'napunsaktha': 52375,\n",
              " 'workmanship': 30612,\n",
              " 'reisner': 52376,\n",
              " \"sanford's\": 61306,\n",
              " '\\x91doña': 52377,\n",
              " 'modest': 6108,\n",
              " \"everything's\": 19153,\n",
              " 'hamer': 40966,\n",
              " \"couldn't'\": 52379,\n",
              " 'quibble': 13001,\n",
              " 'socking': 52380,\n",
              " 'tingler': 21931,\n",
              " 'gutman': 52381,\n",
              " 'lachlan': 40967,\n",
              " 'tableaus': 52382,\n",
              " 'headbanger': 52383,\n",
              " 'spoken': 2847,\n",
              " 'cerebrally': 34768,\n",
              " \"'road\": 23490,\n",
              " 'tableaux': 21932,\n",
              " \"proust's\": 40968,\n",
              " 'periodical': 40969,\n",
              " \"shoveller's\": 52385,\n",
              " 'tamara': 25263,\n",
              " 'affords': 17641,\n",
              " 'concert': 3249,\n",
              " \"yara's\": 87955,\n",
              " 'someome': 52386,\n",
              " 'lingering': 8424,\n",
              " \"abraham's\": 41511,\n",
              " 'beesley': 34769,\n",
              " 'cherbourg': 34770,\n",
              " 'kagan': 28624,\n",
              " 'snatch': 9097,\n",
              " \"miyazaki's\": 9260,\n",
              " 'absorbs': 25264,\n",
              " \"koltai's\": 40970,\n",
              " 'tingled': 64027,\n",
              " 'crossroads': 19511,\n",
              " 'rehab': 16121,\n",
              " 'falworth': 52389,\n",
              " 'sequals': 52390,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrmgGOnJxVwL",
        "outputId": "b9d47de8-679f-435e-c8c0-ef4e9f680cac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "decoded_review # 展示实际评论"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nivIcIGTuGV0"
      },
      "source": [
        "### Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW5oZKb1uGV1"
      },
      "source": [
        "**Encoding the integer sequences via one-hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLwwrto-ymnJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYZiDiSFuGV1",
        "outputId": "a04a2d52-1e5a-48f7-8f16-10df88df7521"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTkDSxSvuGV2"
      },
      "source": [
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ga0np0IuGV2"
      },
      "source": [
        "### Building your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZiR15RnuGV2"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXgp3fB2zhzG"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwZgdY86uGV2"
      },
      "source": [
        "**Compiling the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VQKXKu4uGV3"
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeRLyX3KuGV3"
      },
      "source": [
        "### Validating your approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OekwkSXiuGV3"
      },
      "source": [
        "**Setting aside a validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-BQXNVCuGV3"
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xFMVn2cuGV3"
      },
      "source": [
        "**Training your model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmbv-Y1WuGV4",
        "outputId": "4fe72d2e-7065-4d9c-ae75-d7d8e7b22eaf"
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.5096 - accuracy: 0.7929 - val_loss: 0.3789 - val_accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.3036 - accuracy: 0.9020 - val_loss: 0.3063 - val_accuracy: 0.8855\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.2245 - accuracy: 0.9267 - val_loss: 0.2783 - val_accuracy: 0.8902\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.1760 - accuracy: 0.9429 - val_loss: 0.2737 - val_accuracy: 0.8915\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.2794 - val_accuracy: 0.8906\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.1190 - accuracy: 0.9625 - val_loss: 0.2981 - val_accuracy: 0.8844\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0969 - accuracy: 0.9707 - val_loss: 0.3093 - val_accuracy: 0.8824\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0786 - accuracy: 0.9786 - val_loss: 0.3314 - val_accuracy: 0.8825\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0651 - accuracy: 0.9824 - val_loss: 0.3502 - val_accuracy: 0.8789\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0534 - accuracy: 0.9871 - val_loss: 0.3781 - val_accuracy: 0.8765\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0433 - accuracy: 0.9898 - val_loss: 0.4041 - val_accuracy: 0.8752\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0347 - accuracy: 0.9929 - val_loss: 0.4349 - val_accuracy: 0.8729\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0290 - accuracy: 0.9935 - val_loss: 0.4595 - val_accuracy: 0.8750\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0198 - accuracy: 0.9971 - val_loss: 0.4977 - val_accuracy: 0.8724\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.5334 - val_accuracy: 0.8703\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 0.5737 - val_accuracy: 0.8643\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.5851 - val_accuracy: 0.8705\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.6159 - val_accuracy: 0.8697\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.6486 - val_accuracy: 0.8693\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.6855 - val_accuracy: 0.8669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6KK4BBxuGV4",
        "outputId": "0c6ded58-9dc6-4e00-8276-2fedf82a2c02"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_avrB_X4uGV4"
      },
      "source": [
        "**Plotting the training and validation loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "MvNW4Os_uGV4",
        "outputId": "1817bb57-8a4c-4263-9d97-7835688a5d39"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc7lU7M6uGV4"
      },
      "source": [
        "**Plotting the training and validation accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LnMxnEaFuGV5",
        "outputId": "2c0de2ec-bbec-40b8-ae7f-1b7db785f498"
      },
      "source": [
        "plt.clf()\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsi8uS-quGV5"
      },
      "source": [
        "**Retraining a model from scratch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sed8GV1uuGV5",
        "outputId": "8dc708bf-cfd7-49b3-a081-4c8386358a1f"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 2s 30ms/step - loss: 0.4558 - accuracy: 0.8148\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.2606 - accuracy: 0.9104\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.1999 - accuracy: 0.9297\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.1684 - accuracy: 0.9415\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.2935 - accuracy: 0.8852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZd-mgNZuGV5",
        "outputId": "0225fed4-7c9b-43dd-f70b-38d4cf455005"
      },
      "source": [
        "results"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2935391366481781, 0.8852400183677673]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv-VaTFFuGV5"
      },
      "source": [
        "### Using a trained model to generate predictions on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "PVKC8M-6uGV6",
        "outputId": "8d7ff7ef-0bf2-460f-b51a-aeb7de5beddf"
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a556f0421074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SoumDVN03O4",
        "outputId": "d9badb25-b84e-4732-c5c5-e00ff70ddb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vl1UJxAuGV6"
      },
      "source": [
        "### Further experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6rf91CZuGV6"
      },
      "source": [
        "### Wrapping up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1KyLR4XuGV6"
      },
      "source": [
        "## Classifying newswires: a multiclass classification example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEyJRmNpuGV6"
      },
      "source": [
        "### The Reuters dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4saws9GYuGV6"
      },
      "source": [
        "**Loading the Reuters dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp9v_xSduGV6"
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
        "    num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAh0GHbVuGV7"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKY0qS46uGV7"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq0XYkx-uGV7"
      },
      "source": [
        "train_data[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLLVPVDcuGV7"
      },
      "source": [
        "**Decoding newswires back to text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO6bksJfuGV7"
      },
      "source": [
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "decoded_newswire = \" \".join([reverse_word_index.get(i - 3, \"?\") for i in\n",
        "    train_data[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T2L6mYGuGV8"
      },
      "source": [
        "train_labels[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utd2PF3JuGV8"
      },
      "source": [
        "### Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkW8O86auGV8"
      },
      "source": [
        "**Encoding the input data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAZHi1rHuGV8"
      },
      "source": [
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frn01lzyuGV8"
      },
      "source": [
        "**Encoding the labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmG4DzgfuGV8"
      },
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05GgeWZDuGV9"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k934HSezuGV9"
      },
      "source": [
        "### Building your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df-dAS5kuGV9"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHV98mdOuGV9"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfn5y3YSuGV9"
      },
      "source": [
        "**Compiling the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8SHghW4uGV9"
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWdaSWtAuGV-"
      },
      "source": [
        "### Validating your approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyhicWwRuGV-"
      },
      "source": [
        "**Setting aside a validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejJWhNFiuGV-"
      },
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmkernz-uGV-"
      },
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f-MqRsZuGV-"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwUlNIi5uGV-"
      },
      "source": [
        "**Plotting the training and validation loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RK9nszguGV_"
      },
      "source": [
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv1QgCVMuGV_"
      },
      "source": [
        "**Plotting the training and validation accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X50bwj4NuGV_"
      },
      "source": [
        "plt.clf()\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXPzV-3juGV_"
      },
      "source": [
        "**Retraining a model from scratch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwHL99D-uGV_"
      },
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=9,\n",
        "          batch_size=512,\n",
        "          validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8GK2tKfuGWA"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oquJdG-NuGWA"
      },
      "source": [
        "import copy\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
        "float(np.sum(hits_array)) / len(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGvSjKfduGWA"
      },
      "source": [
        "### Generating predictions on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hvEeDLYuGWA"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnBFvIyKuGWB"
      },
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OruuQQgKuGWB"
      },
      "source": [
        "np.sum(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr_hZRDNuGWB"
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjGaVExQuGWB"
      },
      "source": [
        "### A different way to handle the labels and the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3xk6jMPuGWB"
      },
      "source": [
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ed86B60uGWC"
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csoPvHsTuGWC"
      },
      "source": [
        "### The importance of having sufficiently large intermediate layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXPPkjW9uGWC"
      },
      "source": [
        "**A model with an information bottleneck**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y-Jr2UOuGWC"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5O0uIuxuGWC"
      },
      "source": [
        "### Further experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx75cHkkuGWC"
      },
      "source": [
        "### Wrapping up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWsEC2CzuGWD"
      },
      "source": [
        "## Predicting house prices: a regression example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTB7iEhxuGWD"
      },
      "source": [
        "### The Boston Housing Price dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OiQMhBcuGWD"
      },
      "source": [
        "**Loading the Boston housing dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRsSY0fhuGWD"
      },
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Iw3VNFuGWD"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pN-jeMruGWD"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37o14YE-uGWE"
      },
      "source": [
        "train_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S32Jy_LYuGWE"
      },
      "source": [
        "### Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlszRaqbuGWE"
      },
      "source": [
        "**Normalizing the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOkrvhUruGWE"
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPWRLDbFuGWE"
      },
      "source": [
        "### Building your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qwgdOTmuGWE"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mJVtMIHuGWE"
      },
      "source": [
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbKex8xHuGWF"
      },
      "source": [
        "### Validating your approach using K-fold validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXAw01xfuGWF"
      },
      "source": [
        "**K-fold validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx5YcZHjuGWF"
      },
      "source": [
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        "    print(f\"Processing fold #{i}\")\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model()\n",
        "    model.fit(partial_train_data, partial_train_targets,\n",
        "              epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HuJAIy8uGWF"
      },
      "source": [
        "all_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPf-eUMTuGWF"
      },
      "source": [
        "np.mean(all_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsDKWcfuuGWF"
      },
      "source": [
        "**Saving the validation logs at each fold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x03Zdb30uGWG"
      },
      "source": [
        "num_epochs = 500\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "    print(f\"Processing fold #{i}\")\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model()\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    mae_history = history.history[\"val_mae\"]\n",
        "    all_mae_histories.append(mae_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA2nngbTuGWG"
      },
      "source": [
        "**Building the history of successive mean K-fold validation scores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APYFmlg0uGWG"
      },
      "source": [
        "average_mae_history = [\n",
        "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OE40RueuGWG"
      },
      "source": [
        "**Plotting validation scores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUd_nJV-uGWG"
      },
      "source": [
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation MAE\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Llb97-juGWH"
      },
      "source": [
        "**Plotting smoothed validation scores, excluding the first 10 data points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u59QqNbruGWH"
      },
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
        "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation MAE\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErUmDqRhuGWH"
      },
      "source": [
        "**Training the final model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUWJe3rduGWH"
      },
      "source": [
        "model = build_model()\n",
        "model.fit(train_data, train_targets,\n",
        "          epochs=80, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE9Gxns_uGWH"
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INQqrQBHuGWI"
      },
      "source": [
        "### Generating predictions on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPMAj1BduGWI"
      },
      "source": [
        "predictions = model.predict(test_data)\n",
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k87Vq_2AuGWI"
      },
      "source": [
        "### Wrapping up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwFzuvXIuGWI"
      },
      "source": [
        "## Chapter summary"
      ]
    }
  ]
}