{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow get-started\n",
    "\n",
    "## Tensor\n",
    "rank: 维度\n",
    "\n",
    "[1,2,3] # rank = 1 shape = [3]\n",
    "\n",
    "[[1,2,3], [3,4,5]] # rank = 2, shape = [2,3]\n",
    "\n",
    "[[[1,2,3]],[[7,8,9]]] # rank = 3, shape = [2,1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算图\n",
    "建立计算图 -> 执行计算过程\n",
    "结点表示一个tensor，而边表示一个operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0)  # 同样也是float32，是default的\n",
    "print node1, node2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似lazy load的概念，只有建图建完之后，调用session去运行才会真的开始计算，得出其value值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print sess.run([node1, node2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.0, 4.0)\n"
     ]
    }
   ],
   "source": [
    "print sess.run((node1, node2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print sess.run(node1+node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**operation 也是nodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3: Tensor(\"Add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print 'node3:', node3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "print 'sess.run(node3):', sess.run(node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholder\n",
    "<font color='blue'>\n",
    "一个图可以参数化来接受未来的外部输入；相当于先占坑？\n",
    "\n",
    "就像下面这些命令，其实就类似于申明了一个宏函数，之后会给其中的参数进行赋值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "\n",
    "adder_node = a + b\n",
    "\n",
    "# 给占位符赋值\n",
    "sess.run(adder_node, {a:3, b: 4.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(4.0, dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(a, {a:4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  7.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(adder_node, {a:[1,3], b:[2,4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_3 = adder_node * 3\n",
    "sess.run(add_3, {a:5, b:6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable:\n",
    "<font color='red'>\n",
    "上面的placeholder不能作为变量被迭代，Variable是一个可以训练的结点\n",
    "将可训练迭代的参数放入图中；包含一个初始值及数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "\n",
    "# 为了初始化所有的变量，得call一个init\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print sess.run(linear_model, {x:[1,2,3,4]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们有一个模型，但是需要评估拟合的好坏；需要一个y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_error = tf.square(linear_model - y)\n",
    "loss =  tf.reduce_sum(squared_error)\n",
    "print sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想要改变某一个变量的值，直接使用`assign`给它一个固定的值，则(这里-1和1分别是我事先知晓的最优值)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.train API\n",
    "<font color='blue'>\n",
    "tensorflow中对变量进行自动求导，使用多种优化算法进行迭代\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) # learning rate为0.01\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init)\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "    \n",
    "print sess.run([W,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整个过程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.97351521] b: [ 0.92213166] loss: 0.00101268\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "\n",
    "# model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "linear_model = W * x + b\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_mean(tf.square(linear_model - y))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01) # 学习率为0.01\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 训练数据给定\n",
    "x_train = [1,2,3,4]\n",
    "y_train = [0,-1,-2,-3]\n",
    "\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:x_train, y:y_train})\n",
    "\n",
    "# 评估结果\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.tensorflow.org/images/getting_started_final.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.contrib.learn\n",
    "是一个包装更好的库，将许多模型封装在里面\n",
    "\n",
    "上面的线性模型会变成啥样？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpMCsAEu\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x438a410>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpMCsAEu/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.5, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2041.9\n",
      "INFO:tensorflow:loss = 0.0420674, step = 101\n",
      "INFO:tensorflow:global_step/sec: 2255.35\n",
      "INFO:tensorflow:loss = 0.0153526, step = 201\n",
      "INFO:tensorflow:global_step/sec: 2317.12\n",
      "INFO:tensorflow:loss = 0.00173564, step = 301\n",
      "INFO:tensorflow:global_step/sec: 2103.01\n",
      "INFO:tensorflow:loss = 0.000656267, step = 401\n",
      "INFO:tensorflow:global_step/sec: 2223.56\n",
      "INFO:tensorflow:loss = 0.000294125, step = 501\n",
      "INFO:tensorflow:global_step/sec: 2227.96\n",
      "INFO:tensorflow:loss = 3.53269e-05, step = 601\n",
      "INFO:tensorflow:global_step/sec: 1930.99\n",
      "INFO:tensorflow:loss = 7.48746e-06, step = 701\n",
      "INFO:tensorflow:global_step/sec: 2423.42\n",
      "INFO:tensorflow:loss = 5.26285e-07, step = 801\n",
      "INFO:tensorflow:global_step/sec: 3209.45\n",
      "INFO:tensorflow:loss = 2.21136e-07, step = 901\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpMCsAEu/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.06438e-07.\n",
      "LinearRegressor(params={'gradient_clip_norm': None, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x616ec50>, 'joint_weights': False, 'optimizer': None, 'feature_columns': [_RealValuedColumn(column_name='x', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)]})\n"
     ]
    }
   ],
   "source": [
    "features = [tf.contrib.layers.real_valued_column('x', dimension = 1)]\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns= features)\n",
    "\n",
    "x = np.array([1.,2.,3.,4.])\n",
    "y = np.array([0.,-1.,-2.,-3.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({'x':x}, y, batch_size=4,\n",
    "                                             num_epochs=1000)\n",
    "\n",
    "print estimator.fit(input_fn=input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpXX4zHu\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x68798d0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpXX4zHu/model.ckpt.\n",
      "INFO:tensorflow:loss = 64.4539302474, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2064.57\n",
      "INFO:tensorflow:loss = 0.35915544938, step = 101\n",
      "INFO:tensorflow:global_step/sec: 1810.91\n",
      "INFO:tensorflow:loss = 0.108508009629, step = 201\n",
      "INFO:tensorflow:global_step/sec: 2199.34\n",
      "INFO:tensorflow:loss = 0.159705616354, step = 301\n",
      "INFO:tensorflow:global_step/sec: 2187.22\n",
      "INFO:tensorflow:loss = 0.149157923405, step = 401\n",
      "INFO:tensorflow:global_step/sec: 2033.47\n",
      "INFO:tensorflow:loss = 0.00637787483875, step = 501\n",
      "INFO:tensorflow:global_step/sec: 2198\n",
      "INFO:tensorflow:loss = 0.0219541256541, step = 601\n",
      "INFO:tensorflow:global_step/sec: 2128.34\n",
      "INFO:tensorflow:loss = 0.00432980816077, step = 701\n",
      "INFO:tensorflow:global_step/sec: 2662.48\n",
      "INFO:tensorflow:loss = 0.00956081774882, step = 801\n",
      "INFO:tensorflow:global_step/sec: 3186.85\n",
      "INFO:tensorflow:loss = 0.00763545202846, step = 901\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpXX4zHu/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00166194667955.\n",
      "INFO:tensorflow:Starting evaluation at 2017-05-07-07:03:33\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2017-05-07-07:03:33\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.00147275\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "{'loss': 0.001472755, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 自定义一个model\n",
    "def model(features, labels, mode):\n",
    "    # 线性回归\n",
    "    W = tf.get_variable('W', [1], dtype = tf.float64)\n",
    "    b = tf.get_variable('b', [1], dtype=tf.float64)\n",
    "    y = W*features['x'] + b\n",
    "    \n",
    "    # loss sub-graph\n",
    "    loss = tf.reduce_mean(tf.square(y - labels))\n",
    "    \n",
    "    # trainning sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                    tf.assign_add(global_step, 1))\n",
    "    return tf.contrib.learn.ModelFnOps(\n",
    "    mode=mode, predictions=y,\n",
    "    loss = loss, train_op=train)\n",
    "    \n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model)\n",
    "# define our data set\n",
    "x = np.array([1., 2., 3., 4.])\n",
    "y = np.array([0., -1., -2., -3.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x}, y, 4, num_epochs=1000)\n",
    "\n",
    "# train\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "# evaluate our model\n",
    "print(estimator.evaluate(input_fn=input_fn, steps=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST for Beginners\n",
    "读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Variables\n",
    "\n",
    "储存并更新参数，必须被初始化；同时可以被存储在磁盘中；因此可以被reload；\n",
    "\n",
    "## 创建Variable\n",
    "Variable包含tensor，需要指定其shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35),\n",
    "                                  name = 'weights' )\n",
    "biases = tf.Variable(tf.zeros([200]), name = 'biases')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "声明tf.Variable会给graph加上如下这些op，op可以理解为边：\n",
    "\n",
    "+ a variable op ：保存variable的值\n",
    "+ 一个initializer op：初始化variable的值；实际上是一个tf.assign op\n",
    "+ 初始值上的op也被保存在计算图中；\n",
    "\n",
    "tf.Variable 是一个class，每一次生成就是一个实例；\n",
    "他可以被存在一个特定的device中；对variable的操作必须在同一个设备中。\n",
    "\n",
    "## initialization\n",
    "\n",
    "变量的初始化必须在model的所有op操作之前run；最简单的方式就是添加一个op来讲所有初始化变量都run一遍\n",
    "\n",
    "tf.global_variables_initializer()；在搭完积木之后，在sess.run中进行此op的运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.ops.variables.Variable at 0x2fe0fd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x4cb0490>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 新建两个Variable\n",
    "weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35),\n",
    "                                  name = 'weights')\n",
    "biases = tf.Variable(tf.zeros([200], name = \"biases\"))\n",
    "\n",
    "# 添加一个op来初始化变量\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# launch the model\n",
    "with tf.Session() as sess:\n",
    "    # run the init op\n",
    "    sess.run(init_op)\n",
    "    # use the model\n",
    "    \n",
    "# 查看一下两个Variable\n",
    "weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"weights_1/read:0\", shape=(784, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从另一个Variable处assign来初始化\n",
    "需要用别的变量的initialized_value()来赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 新建一个变量\n",
    "weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35),\n",
    "                                  name = 'weights')\n",
    "\n",
    "w2 = tf.Variable(weights.initialized_value(), name = 'w2')\n",
    "\n",
    "w_twice = tf.Variable(weights.initialized_value() * 2, name = 'w_twice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom initialization\n",
    "也可以指定其初始化的变量列表；这样就不需要初始化所有变量了\n",
    "\n",
    "## saving and restoring\n",
    "最简单的方式就是使用tf.train.Saver来做\n",
    "此构造函数添加了  save  和 restore  两个op 给指定的或计算图中的所有Variable\n",
    "\n",
    "### checkpoint Files\n",
    "Variables 被存在一个二进制文件中，包含了从Variable名字到tensor 值之间的一个map；\n",
    "\n",
    "当你新建一个Saver对象时，你可以自己选择需要包含的Variable的名字。\n",
    "\n",
    "### saving Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save in file: /tmp/model1.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 新建Variable\n",
    "v1 = tf.Variable(tf.random_normal([200, 768], stddev=0.35),\n",
    "                          name = 'v1')\n",
    "v2 = tf.Variable(tf.zeros([200]), name = 'v2')\n",
    "\n",
    "# init the Variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# save 也是一个op\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# session\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # save the Varibales to disk\n",
    "    save_path = saver.save(sess, '/tmp/model1.ckpt')\n",
    "    print 'model save in file: %s' % save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### restoring Variables\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create some variables.\n",
    "v1 = tf.Variable(..., name=\"v1\")\n",
    "v2 = tf.Variable(..., name=\"v2\")\n",
    "...\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "  # Do some work with the model\n",
    "  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义那些Variable需要被save和restore\n",
    "如果不给tf.train.saver传任何参数，则默认会将所有Variable保存；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = tf.Variable(tf.random_normal([200, 768], stddev=0.35),\n",
    "                          name = 'v1')\n",
    "v2 = tf.Variable(tf.zeros([200]), name = 'v2')\n",
    "\n",
    "# 只保留v2，用dict字典来指定\n",
    "saver = tf.train.Saver({'my_v2': v2})  # 保存的名字叫做my_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tensor 中的 ranks， shapes，types\n",
    "\n",
    "### rank\n",
    "\n",
    "维度；\n",
    "下面的tensor有几个维度？rank为几？\n",
    "\n",
    "t=[[1,2,3], [4,5,6],[7,8,9]   # 2维\n",
    "\n",
    "\n",
    "|Rank|\tMath entity\t|Python example\n",
    "|-------|----------|-------|\n",
    "|0\t|Scalar (magnitude only)\t|s = 483\n",
    "|1\t|Vector (magnitude and direction)|\tv = [1.1, 2.2, 3.3]\n",
    "|2\t|Matrix (table of numbers)|\tm = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "|3\t|3-Tensor (cube of numbers)\t|t = [[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]]\n",
    "|n\t|n-Tensor (you get the idea)\t|....\n",
    "\n",
    "\n",
    "### shape\n",
    "\n",
    "|阶\t|形状|\t维数|\t实例\n",
    "|-----|--------|------------|\n",
    "|0\t|[ ]|\t0-D\t|一个 0维张量. 一个纯量.|\n",
    "|1|\t[D0]|\t1-D\t|一个1维张量的形式[5].|\n",
    "|2\t|[D0, D1]\t|2-D\t|一个2维张量的形式[3, 4].|\n",
    "|3|\t[D0, D1, D2]\t|3-D|\t一个3维张量的形式 [1, 4, 3].|\n",
    "|n|\t[D0, D1, ... Dn]|\tn-D\t|一个n维张量的形式 [D0, D1, ... Dn].|\n",
    "\n",
    "### data types\n",
    "\n",
    "|数据类型\t|Python 类型\t|描述\n",
    "|--------|----------------|----------------\n",
    "|DT_FLOAT|\ttf.float32\t|32 位浮点数.\n",
    "|DT_DOUBLE\t|tf.float64\t|64 位浮点数.\n",
    "|DT_INT64\t|tf.int64|\t64 位有符号整型.\n",
    "|DT_INT32\t|tf.int32|\t32 位有符号整型.\n",
    "|DT_INT16\t|tf.int16|\t16 位有符号整型.\n",
    "|DT_INT8\t|tf.int8|\t8 位有符号整型.\n",
    "|DT_UINT8\t|tf.uint8\t|8 位无符号整型.\n",
    "|DT_STRING\t|tf.string|\t可变长度的字节数组.每一个张量元素都是一个字节数组.\n",
    "|DT_BOOL\t|tf.bool\t|布尔型.\n",
    "|DT_COMPLEX64\t|tf.complex64|\t由两个32位浮点数组成的复数:实数和虚数.\n",
    "|DT_QINT32\t|tf.qint32|\t用于量化Ops的32位有符号整型.\n",
    "|DT_QINT8\t|tf.qint8\t|用于量化Ops的8位有符号整型.\n",
    "|DT_QUINT8\t|tf.quint8|\t用于量化Ops的8位无符号整型."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
