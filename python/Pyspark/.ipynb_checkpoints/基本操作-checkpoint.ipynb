{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import Column, col, lit\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.31.92:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11ac588d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import SparkSession from pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create my_spark;当已经存在sparksession时，会载入\n",
    "my_spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Print my_spark\n",
    "my_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.31.92:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看Sparksession中的表格\n",
    "my_spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  3\n",
       "1  2  4\n",
       "2  3  5\n",
       "3  4  6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({\"a\":[1,2,3,4], 'b':[3,4,5,6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  a|  b|\n",
      "+---+---+\n",
      "|  1|  3|\n",
      "|  2|  4|\n",
      "|  3|  5|\n",
      "|  4|  6|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = my_spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意，此处createDataFrame()产生的SparkDataFrame只是locally的，没有存在SparkSession中\n",
    "\n",
    "\n",
    "需要将其存入sparksession中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='test_pandas', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.createTempView(\"test_pandas\")\n",
    "my_spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Don't change this file path\n",
    "file_path = \"/usr/local/share/datasets/airports.csv\"\n",
    "\n",
    "# Read in the airports data\n",
    "airports = spark.read.csv(file_path, header=True)\n",
    "\n",
    "# Show the data\n",
    "airports.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chapter 6 working with different types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义schema，StructType由StructField组成每一个StructField包含:\n",
    "+ 列名\n",
    "+ 列的数据格式\n",
    "+ 这一列是否可以包含缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"InvoiceNo\", LongType(), True),\n",
    "    StructField(\"StockCode\", StringType(), True),\n",
    "    StructField(\"Description\", StringType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True),\n",
    "    StructField(\"InvoiceDate\", TimestampType(), True),\n",
    "    StructField(\"UnitPrice\", FloatType(), True),\n",
    "    StructField(\"CustomerID\", FloatType(), True),\n",
    "    StructField(\"Country\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = my_spark.read.csv('./2010-12-01.csv', sep='\\t', header=True, schema=schema)\n",
    "df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: long (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: float (nullable = true)\n",
      " |-- CustomerID: float (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'some'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Country: string]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(col('Country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select('Country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------+--------------+\n",
      "|       Country|       Country|  expr_country|       Country|\n",
      "+--------------+--------------+--------------+--------------+\n",
      "|United Kingdom|United Kingdom|United Kingdom|United Kingdom|\n",
      "|United Kingdom|United Kingdom|United Kingdom|United Kingdom|\n",
      "+--------------+--------------+--------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "df.select(\"Country\",\n",
    "          expr(\"Country\"),\n",
    "          expr(\"Country as expr_country\"),\n",
    "         col(\"Country\"))\\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+\n",
      "|(UnitPrice + 1)|((UnitPrice * 2) + 1)|\n",
      "+---------------+---------------------+\n",
      "|           3.55|                  6.1|\n",
      "|      4.3900003|                 7.78|\n",
      "+---------------+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 定义一些操作来看看\n",
    "t1 = col(\"UnitPrice\")+1\n",
    "t2 = col(\"UnitPrice\") * 2 + 1\n",
    "df.select(t1, t2).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     test|\n",
      "+---------+\n",
      "|     3.55|\n",
      "|4.3900003|\n",
      "+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 利用expr\n",
    "from pyspark.sql.functions import expr\n",
    "df.select(expr(\"UnitPrice+1 as test\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(InvoiceNo=536365, StockCode='85123A', Description='WHITE HANGING HEART T-LIGHT HOLDER', Quantity=6, InvoiceDate=datetime.datetime(2010, 12, 1, 8, 26), UnitPrice=2.549999952316284, CustomerID=17850.0, Country='United Kingdom')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'InvoiceNo'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(InvoiceNo=536365, StockCode='85123A', Description='WHITE HANGING HEART T-LIGHT HOLDER', Quantity=6, InvoiceDate=datetime.datetime(2010, 12, 1, 8, 26), UnitPrice=2.549999952316284, CustomerID=17850.0, Country='United Kingdom')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(InvoiceNo=536365, StockCode='85123A', Description='WHITE HANGING HEART T-LIGHT HOLDER', Quantity=6, InvoiceDate=datetime.datetime(2010, 12, 1, 8, 26), UnitPrice=2.549999952316284, CustomerID=17850.0, Country='United Kingdom')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=11, name='Alice')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "row = Row(name=\"Alice\", age=11)\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**从Row新建DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| some| col|names|\n",
      "+-----+----+-----+\n",
      "|hello|null|    1|\n",
      "|world|null|    3|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "myschema = StructType([\n",
    "    StructField(\"some\", StringType(), True),\n",
    "    StructField(\"col\", StringType(), True),\n",
    "    StructField(\"names\", StringType(), True)\n",
    "])\n",
    "\n",
    "myRow = [Row(\"hello\", None, 1), Row(\"world\", None, 3)]\n",
    "myDF = my_spark.createDataFrame(myRow, myschema)\n",
    "myDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|       Country|Unitprice|\n",
      "+--------------+---------+\n",
      "|United Kingdom|     2.55|\n",
      "|United Kingdom|     3.39|\n",
      "+--------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Country\", \"Unitprice\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------------+\n",
      "|Unitprice|      new|Unitprice|(Unitprice + 1)|\n",
      "+---------+---------+---------+---------------+\n",
      "|     2.55|     3.55|     2.55|           3.55|\n",
      "|     3.39|4.3900003|     3.39|      4.3900003|\n",
      "+---------+---------+---------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, column, expr\n",
    "df.select(\"Unitprice\",\n",
    "         expr(\"Unitprice+1 as new\"),\n",
    "         col(\"Unitprice\"),\n",
    "         col(\"Unitprice\")+1).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|      new|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|     3.55|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|4.3900003|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selctexpr\n",
    "df.selectExpr(\"*\",\n",
    "              \"Unitprice+1 as new\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候需要将普通数值转化为sparkType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|One|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|  1|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|  1|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select(expr(\"*\"), lit(1).alias(\"One\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|新的一列|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|       5|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|       5|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"新的一列\", lit(5)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|新的一列|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|   false|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|   false|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"新的一列\", expr(\"Country == 'United States'\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|  重命名为国家|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 重命名\n",
    "df.withColumnRenamed(\"Country\", \"重命名为国家\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 删除列\n",
    "df=df.withColumn(\"new\",lit(2))\n",
    "df=df.drop(col(\"new\"))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
      "|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
      "|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
      "|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|United Kingdom|\n",
      "|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|United Kingdom|\n",
      "|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|United Kingdom|\n",
      "|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|United Kingdom|\n",
      "|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|United Kingdom|\n",
      "|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|United Kingdom|\n",
      "+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.drop(*['InvoiceNo', 'StockCode'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|new|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|   536381|    71270|     PHOTO CLIP LINE|       1|2010-12-01 09:41:00|     1.25|   15311.0|United Kingdom|  2|\n",
      "|   536381|    22262|FELT EGG COSY CHI...|       1|2010-12-01 09:41:00|     0.85|   15311.0|United Kingdom|  2|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"Quantity\")<2).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|new|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|   536381|    71270|     PHOTO CLIP LINE|       1|2010-12-01 09:41:00|     1.25|   15311.0|United Kingdom|  2|\n",
      "|   536381|    22262|FELT EGG COSY CHI...|       1|2010-12-01 09:41:00|     0.85|   15311.0|United Kingdom|  2|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"Quantity\")<2).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|new|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|   536381|    71270|     PHOTO CLIP LINE|       1|2010-12-01 09:41:00|     1.25|   15311.0|United Kingdom|  2|\n",
      "|   536381|    22262|FELT EGG COSY CHI...|       1|2010-12-01 09:41:00|     0.85|   15311.0|United Kingdom|  2|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(expr(\"Quantity<2\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[InvoiceNo: bigint, StockCode: string, Description: string, Quantity: int, InvoiceDate: timestamp, UnitPrice: float, CustomerID: float, Country: string, new: int]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新分区\n",
    "df.repartition(5, col(\"Country\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(InvoiceNo=536365, StockCode='85123A', Description='WHITE HANGING HEART T-LIGHT HOLDER', Quantity=6, InvoiceDate=datetime.datetime(2010, 12, 1, 8, 26), UnitPrice=2.549999952316284, CustomerID=17850.0, Country='United Kingdom', new=2),\n",
       " Row(InvoiceNo=536365, StockCode='71053', Description='WHITE METAL LANTERN', Quantity=6, InvoiceDate=datetime.datetime(2010, 12, 1, 8, 26), UnitPrice=3.390000104904175, CustomerID=17850.0, Country='United Kingdom', new=2)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect\n",
    "collectDF = df.limit(2).collect()\n",
    "collectDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='df_2010_01', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='test_pandas', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 存入sparksession\n",
    "df.createOrReplaceTempView('df_2010_01')\n",
    "my_spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql语法\n",
    "my_spark.sql('select * from df_2010_01 limit 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to spark type\n",
    "df.select(lit(5), lit('five'), lit(5.0)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# working with boolen\n",
    "from pyspark.sql.functions import instr\n",
    "pricefilter = col('UnitPrice')  > 200\n",
    "descripFilter = instr(df.Description, 'POSTAGE') >= 1\n",
    "df.where(df.StockCode.isin('DOT')).where(pricefilter | descripFilter).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|isExpensive|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|      false|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|      false|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|      false|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|      false|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|      false|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DOTCodeFilter = col('StockCode') == 'DOT'\n",
    "df.withColumn('isExpensive', DOTCodeFilter & (pricefilter | descripFilter)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|isExpensive|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|      false|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|      false|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|      false|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|      false|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|      false|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('isExpensive', DOTCodeFilter & (pricefilter | descripFilter)).where('!isExpensive').show(5) # 非"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|isExpensive|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|       true|\n",
      "|   536373|   85123A|WHITE HANGING HEA...|       6|2010-12-01 09:02:00|     2.55|   17850.0|United Kingdom|       true|\n",
      "|   536375|   85123A|WHITE HANGING HEA...|       6|2010-12-01 09:32:00|     2.55|   17850.0|United Kingdom|       true|\n",
      "|   536390|   85123A|WHITE HANGING HEA...|      64|2010-12-01 10:19:00|     2.55|   17511.0|United Kingdom|       true|\n",
      "|   536394|   85123A|WHITE HANGING HEA...|      32|2010-12-01 10:39:00|     2.55|   13408.0|United Kingdom|       true|\n",
      "|   536396|   85123A|WHITE HANGING HEA...|       6|2010-12-01 10:51:00|     2.55|   17850.0|United Kingdom|       true|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "df.withColumn('isExpensive', expr(\"UnitPrice<= 3.0 and StockCode == '85123A'\")).where('isExpensive').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|     ID|      realQuantity|\n",
      "+-------+------------------+\n",
      "|17850.0|239.08999999999997|\n",
      "|17850.0|          418.7156|\n",
      "+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# working with numbers\n",
    "from pyspark.sql.functions import expr, pow\n",
    "fabricatedQuantity = pow(col('Quantity')* col('UnitPrice'), 2) + 5\n",
    "df.select(expr('CustomerID as ID'), fabricatedQuantity.alias('realQuantity')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|     ID|            总价格|\n",
      "+-------+------------------+\n",
      "|17850.0|239.08999999999997|\n",
      "|17850.0|          418.7156|\n",
      "+-------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all in sql\n",
    "df.selectExpr('CustomerID as ID',\n",
    "             \"POWER((Quantity * UnitPrice), 2.0) + 5 as `总价格`\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------+------------+\n",
      "|CustomerID|UnitPrice|price_round|price_bround|\n",
      "+----------+---------+-----------+------------+\n",
      "|   17850.0|     2.55|          3|           2|\n",
      "|   17850.0|     3.39|          3|           2|\n",
      "|   17850.0|     2.75|          3|           2|\n",
      "|   17850.0|     3.39|          3|           2|\n",
      "|   17850.0|     3.39|          3|           2|\n",
      "+----------+---------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# round & bround\n",
    "df.select('CustomerID', 'UnitPrice', expr('round(2.5) as price_round'), expr('bround(2.5) as price_bround')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n",
      "|summary|        InvoiceNo|         StockCode|         Description|          Quantity|         UnitPrice|        CustomerID|       Country|\n",
      "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n",
      "|  count|              357|               357|                 357|               357|               357|               357|           357|\n",
      "|   mean|536385.3333333334| 29411.22697368421|                null| 18.81232492997199|3.8414005602240917| 15591.70868347339|          null|\n",
      "| stddev|10.67293883779816|19189.381582082537|                null|44.490575500251296| 9.246382605719276|1877.2715511331987|          null|\n",
      "|    min|           536365|             10002|3 STRIPEY MICE FE...|               -24|               0.1|           12431.0|     Australia|\n",
      "|    max|          C536391|              POST|ZINC WILLIE WINKI...|               432|             165.0|           18074.0|United Kingdom|\n",
      "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 五分位数\n",
    "from pyspark.sql.functions import count, mean, stddev_pop, min, max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|StockCode_Quantity| -1|-12|-24|  1| 10|100| 12|120|144| 16| 18|192|  2| 20| 23| 24|288|  3| 32| 36|  4| 40|432| 48|  5| 50|  6| 64|  8| 80|  9| 96|\n",
      "+------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|             22064|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|             21080|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|\n",
      "+------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.stat.crosstab('StockCode', 'Quantity').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "| StockCode_freqItems|  Quantity_freqItems|\n",
      "+--------------------+--------------------+\n",
      "|[84029G, 22068, 8...|[23, 50, 32, 8, -...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.stat.freqItems(['StockCode', 'Quantity']).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------------------------------+\n",
      "|initcap(Description)              |Description                       |\n",
      "+----------------------------------+----------------------------------+\n",
      "|White Hanging Heart T-light Holder|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|White Metal Lantern               |WHITE METAL LANTERN               |\n",
      "+----------------------------------+----------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# working with string\n",
    "from pyspark.sql.functions import initcap\n",
    "df.select(initcap('Description'), 'Description').show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------------------------------+----------------------------------+\n",
      "|Description                       |lower(Description)                |upper(Description)                |\n",
      "+----------------------------------+----------------------------------+----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|white hanging heart t-light holder|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|WHITE METAL LANTERN               |white metal lantern               |WHITE METAL LANTERN               |\n",
      "+----------------------------------+----------------------------------+----------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 大小写切换\n",
    "from pyspark.sql.functions import lower, upper\n",
    "df.select('Description',lower(col('Description')), expr('upper(Description)')).show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+----------------------------+----------+----------+\n",
      "|ltrim                         |rtrim                         |trim                        |lpad      |rpad      |\n",
      "+------------------------------+------------------------------+----------------------------+----------+----------+\n",
      "|左边有空格  看看会不会被去掉  |  右边有空格  看看会不会被去掉|中间有空格  看看会不会被去掉|     HELLO|HELLO     |\n",
      "+------------------------------+------------------------------+----------------------------+----------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 去除字符串中的空格\n",
    "from pyspark.sql.functions import lit, ltrim, rtrim, lpad, rpad, lpad, trim\n",
    "df.select(\n",
    "    ltrim(lit('  左边有空格  看看会不会被去掉  ')).alias('ltrim'),\n",
    "    rtrim(lit('  右边有空格  看看会不会被去掉  ')).alias('rtrim'),\n",
    "    trim(lit('  中间有空格  看看会不会被去掉  ')).alias('trim'),\n",
    "    lpad(lit('HELLO'), 10, ' ').alias('lpad'),  # 表示最终输出有10个字符长度\n",
    "    rpad(lit('HELLO'), 10, ' ').alias('rpad')).show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------------------------------+\n",
      "|color_clean                       |Description                       |\n",
      "+----------------------------------+----------------------------------+\n",
      "|color HANGING HEART T-LIGHT HOLDER|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|color METAL LANTERN               |WHITE METAL LANTERN               |\n",
      "+----------------------------------+----------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 正则表达式匹配\n",
    "from pyspark.sql.functions import regexp_replace, regexp_extract\n",
    "df.select(regexp_replace(\"Description\", 'BLACK|WHITE|RED|GREEN|BLUE', 'color').alias('color_clean'), col('Description')).show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------------------------------+\n",
      "|translate(Description, LEET, 1337)|Description                       |\n",
      "+----------------------------------+----------------------------------+\n",
      "|WHI73 HANGING H3AR7 7-1IGH7 HO1D3R|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|WHI73 M37A1 1AN73RN               |WHITE METAL LANTERN               |\n",
      "+----------------------------------+----------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用translate函数来进行正则匹配替换\n",
    "from pyspark.sql.functions import translate\n",
    "df.select(translate('Description', 'LEET', '1337'), 'Description').show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------------------+\n",
      "|color_clean|Description                       |\n",
      "+-----------+----------------------------------+\n",
      "|WHITE      |WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|WHITE      |WHITE METAL LANTERN               |\n",
      "+-----------+----------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_str = '(BLACK|WHITE|RED|GREEN|BLUE)'\n",
    "df.select(regexp_extract(col('Description'), extract_str, 1).alias('color_clean'),\n",
    "         col('Description')).show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+--------------+\n",
      "|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |hasSimpleColor|\n",
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|true          |\n",
      "|536365   |71053    |WHITE METAL LANTERN               |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|true          |\n",
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check 类似于R的grep\n",
    "from pyspark.sql.functions import instr\n",
    "containsBlack = instr(col('Description'), 'BLACK') >= 1\n",
    "containsWhite = instr(col('Description'), 'WHITE') >= 1\n",
    "df.withColumn('hasSimpleColor', containsBlack | containsWhite).show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+\n",
      "|CustomerID|StockCode|Quantity|\n",
      "+----------+---------+--------+\n",
      "|   17850.0|   85123A|       6|\n",
      "|   17850.0|    71053|       6|\n",
      "+----------+---------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, locate\n",
    "col_list = ['CustomerID', 'StockCode', 'Quantity']\n",
    "df.select(*col_list).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_locator(column, color_string):\n",
    "    return locate(color_string.upper(), column).cast('boolean').alias('is_'+color_string)\n",
    "\n",
    "simpeColors = ['black', 'white', 'red', 'green', 'blue']\n",
    "selectedColumn = [color_locator(df.Description, c) for c in simpeColors]\n",
    "selectedColumn.append(expr('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column<b'CAST(locate(BLACK, Description, 1) AS BOOLEAN) AS `is_black`'>,\n",
       " Column<b'CAST(locate(WHITE, Description, 1) AS BOOLEAN) AS `is_white`'>,\n",
       " Column<b'CAST(locate(RED, Description, 1) AS BOOLEAN) AS `is_red`'>,\n",
       " Column<b'CAST(locate(GREEN, Description, 1) AS BOOLEAN) AS `is_green`'>,\n",
       " Column<b'CAST(locate(BLUE, Description, 1) AS BOOLEAN) AS `is_blue`'>,\n",
       " Column<b'unresolvedstar()'>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|Description                       |\n",
      "+----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|WHITE METAL LANTERN               |\n",
      "|RED WOOLLY HOTTIE WHITE HEART.    |\n",
      "+----------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*selectedColumn).where(expr('is_white OR is_red'))\\\n",
    "   .select('Description').show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date and timestamp\n",
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "dateDF = my_spark.range(10)\\\n",
    "        .withColumn('today', current_date())\\\n",
    "        .withColumn('now', current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------------------+\n",
      "|id |today     |now                    |\n",
      "+---+----------+-----------------------+\n",
      "|0  |2019-06-17|2019-06-17 22:37:47.523|\n",
      "|1  |2019-06-17|2019-06-17 22:37:47.523|\n",
      "+---+----------+-----------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_add(today, 5)|date_sub(today, 2)|\n",
      "+------------------+------------------+\n",
      "|        2019-06-22|        2019-06-15|\n",
      "+------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_add,date_sub\n",
    "dateDF.select(date_add(\"today\", 5), date_sub('today', 2)).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff, months_between, to_date\n",
    "dateDF.withColumn('week_ago', date_sub(col('today'), 7))\\\n",
    "    .select(datediff('week_ago', 'today')).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|months_between(start, end, true)|\n",
      "+--------------------------------+\n",
      "|                     -1.16129032|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(\n",
    "    to_date(lit('2019-01-01')).alias('start'),\n",
    "    to_date(lit('2019-02-06')).alias('end'))\\\n",
    "    .select(months_between(col('start'), col('end'))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------------------+\n",
      "|to_date('2016-13-01')|to_date('2018-12-11')|\n",
      "+---------------------+---------------------+\n",
      "|                 null|           2018-12-11|\n",
      "+---------------------+---------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to_date format\n",
    "dateDF.select(to_date(lit('2016-13-01')), to_date(lit('2018-12-11'))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----------------------------------+\n",
      "|to_date('2016-13-01', 'yyyy-dd-MM')|to_date('2018-12-11', 'yyyy-MM-dd')|\n",
      "+-----------------------------------+-----------------------------------+\n",
      "|                         2016-01-13|                         2018-12-11|\n",
      "+-----------------------------------+-----------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(to_date(lit('2016-13-01'), 'yyyy-dd-MM'), \n",
    "              to_date(lit('2018-12-11'), 'yyyy-MM-dd')).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------+\n",
      "|to_timestamp(`date1`)|     date2|\n",
      "+---------------------+----------+\n",
      "|  2016-01-13 00:00:00|2018-12-11|\n",
      "+---------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "dateDF.select(to_date(lit('2016-13-01'), 'yyyy-dd-MM').alias('date1'), \n",
    "              to_date(lit('2018-12-11'), 'yyyy-MM-dd').alias('date2'))\\\n",
    "    .select(to_timestamp(\"date1\"), \"date2\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------+\n",
      "|coalesce(Description)             |CustomerID|\n",
      "+----------------------------------+----------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|17850.0   |\n",
      "+----------------------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce\n",
    "df.select(coalesce(col('Description')), col('CustomerID')).show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+-----------------+------------------------------------+------------------------------------+\n",
      "|ifnull(NULL, 'return_value')|nullif(NULL, 'value')|nvl(NULL, '哈哈')|nvl2(NULL, '我不是null', '我是null')|nvl2('as', '我不是null', '我是null')|\n",
      "+----------------------------+---------------------+-----------------+------------------------------------+------------------------------------+\n",
      "|                return_value|                 null|             哈哈|                            我是null|                          我不是null|\n",
      "|                return_value|                 null|             哈哈|                            我是null|                          我不是null|\n",
      "+----------------------------+---------------------+-----------------+------------------------------------+------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('ifnull(null, \"return_value\")',\n",
    "             \"nullif(null, 'value')\",\n",
    "             \"nvl(null, '哈哈')\",\n",
    "             \"nvl2(null, '我不是null','我是null')\",\n",
    "             \"nvl2('as', '我不是null', '我是null')\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('ALL null values becomes this value')\n",
    "\n",
    "fill_values = {'StockCode': 5, \"Description\": 6}\n",
    "df.na.fill(fill_values).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null在排序中的顺序\n",
    "# asc_nulls_first, desc_nulls_first, asc_nulls_last, desc_nulls_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|complex                                     |\n",
      "+--------------------------------------------+\n",
      "|[WHITE HANGING HEART T-LIGHT HOLDER, 536365]|\n",
      "|[WHITE METAL LANTERN, 536365]               |\n",
      "+--------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 复杂的数据类型 structs, array, maps\n",
    "df.selectExpr(\"(Description, InvoiceNo) as complex\").show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "complexDF = df.select(struct('Description', 'InvoiceNo').alias('complex_struct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|complex_struct.Description|\n",
      "+--------------------------+\n",
      "|      WHITE HANGING HEA...|\n",
      "|       WHITE METAL LANTERN|\n",
      "+--------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getfiled\n",
    "complexDF.select(col('complex_struct').getField('Description')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|         Description|InvoiceNo|\n",
      "+--------------------+---------+\n",
      "|WHITE HANGING HEA...|   536365|\n",
      "| WHITE METAL LANTERN|   536365|\n",
      "+--------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 自动拆解\n",
    "complexDF.select('complex_struct.*').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|split(Description,  )|\n",
      "+---------------------+\n",
      "| [WHITE, HANGING, ...|\n",
      "| [WHITE, METAL, LA...|\n",
      "+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# arrays\n",
    "from pyspark.sql.functions import split\n",
    "df.select(split('Description', ' ')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|col[0]| col[1]|\n",
      "+------+-------+\n",
      "| WHITE|HANGING|\n",
      "| WHITE|  METAL|\n",
      "+------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split('Description', ' ').alias('col'))\\\n",
    "    .selectExpr('col[0]', 'col[1]').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|size(split(Description,  ))|\n",
      "+---------------------------+\n",
      "|                          5|\n",
      "|                          3|\n",
      "+---------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 计算array的长度\n",
    "from pyspark.sql.functions import size\n",
    "df.select(size(split('Description', ' '))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|col                                     |\n",
      "+----------------------------------------+\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|\n",
      "|[WHITE, METAL, LANTERN]                 |\n",
      "+----------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split('Description', ' ').alias('col')).show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 col|\n",
      "+--------------------+\n",
      "|[WHITE, HANGING, ...|\n",
      "|[WHITE, METAL, LA...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 如何将长度不同的array进行拆分呀\n",
    "df.select(split('Description', ' ').alias('col')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|array_contains(col, WHITE)|\n",
      "+--------------------------+\n",
      "|                      true|\n",
      "|                      true|\n",
      "|                     false|\n",
      "|                     false|\n",
      "|                      true|\n",
      "+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# arrays_contain\n",
    "from pyspark.sql.functions import array_contains\n",
    "df.select(split('Description', ' ').alias('col'))\\\n",
    "    .select(array_contains('col', 'WHITE')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+--------+\n",
      "|col                                     |exploded|\n",
      "+----------------------------------------+--------+\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|WHITE   |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HANGING |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HEART   |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|T-LIGHT |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HOLDER  |\n",
      "|[WHITE, METAL, LANTERN]                 |WHITE   |\n",
      "|[WHITE, METAL, LANTERN]                 |METAL   |\n",
      "|[WHITE, METAL, LANTERN]                 |LANTERN |\n",
      "|[CREAM, CUPID, HEARTS, COAT, HANGER]    |CREAM   |\n",
      "|[CREAM, CUPID, HEARTS, COAT, HANGER]    |CUPID   |\n",
      "+----------------------------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df.select(split('Description', ' ').alias('col'))\\\n",
    "    .withColumn('exploded', explode('col')).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+\n",
      "|Mapped                                        |\n",
      "+----------------------------------------------+\n",
      "|[WHITE HANGING HEART T-LIGHT HOLDER -> 536365]|\n",
      "|[WHITE METAL LANTERN -> 536365]               |\n",
      "+----------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# maps\n",
    "from pyspark.sql.functions import create_map\n",
    "df.select(create_map(col('Description'), col('InvoiceNo')).alias('Mapped')).show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|Mapped[WHITE METAL LANTERN]|\n",
      "+---------------------------+\n",
      "|                       null|\n",
      "|                     536365|\n",
      "+---------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 通过map的键值访问其value\n",
    "df.select(create_map(col('Description'), col('InvoiceNo')).alias('Mapped'))\\\n",
    "    .selectExpr(\"Mapped['WHITE METAL LANTERN']\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                 key| value|\n",
      "+--------------------+------+\n",
      "|WHITE HANGING HEA...|536365|\n",
      "| WHITE METAL LANTERN|536365|\n",
      "+--------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explode to key-value\n",
    "df.select(create_map(col('Description'), col('InvoiceNo')).alias('Mapped'))\\\n",
    "    .selectExpr('explode(Mapped)').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                 key| value|\n",
      "+--------------------+------+\n",
      "|WHITE HANGING HEA...|536365|\n",
      "| WHITE METAL LANTERN|536365|\n",
      "+--------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(create_map(col('Description'), col('InvoiceNo')).alias('Mapped'))\\\n",
    "    .select(explode(\"Mapped\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with json\n",
    "jsonDF = my_spark.range(1).selectExpr(\"\"\"\n",
    "    '{\"myJSONKey\": {\"myJSONValue\": [1,2,3]}}' as jsonString\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|jsonString                             |\n",
      "+---------------------------------------+\n",
      "|{\"myJSONKey\": {\"myJSONValue\": [1,2,3]}}|\n",
      "+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------+\n",
      "|column|c0                     |\n",
      "+------+-----------------------+\n",
      "|2     |{\"myJSONValue\":[1,2,3]}|\n",
      "+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import json_tuple, get_json_object\n",
    "jsonDF.select(\n",
    "    get_json_object(col('jsonString'), \"$.myJSONKey.myJSONValue[1]\").alias('column'),\n",
    "    json_tuple(col('jsonString'), 'myJSONKey')).show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|structstojson(struct)|\n",
      "+---------------------+\n",
      "| {\"Description\":\"W...|\n",
      "+---------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 将struct 转化为json格式\n",
    "from pyspark.sql.functions import to_json\n",
    "df.select(struct('Description', 'InvoiceNO').alias('struct')).select(to_json('struct')).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------+\n",
      "|new                                         |newjson                                                                  |struct                                      |\n",
      "+--------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------+\n",
      "|[536365, WHITE HANGING HEART T-LIGHT HOLDER]|{\"InvoiceNo\":\"536365\",\"Description\":\"WHITE HANGING HEART T-LIGHT HOLDER\"}|[536365, WHITE HANGING HEART T-LIGHT HOLDER]|\n",
      "|[536365, WHITE METAL LANTERN]               |{\"InvoiceNo\":\"536365\",\"Description\":\"WHITE METAL LANTERN\"}               |[536365, WHITE METAL LANTERN]               |\n",
      "+--------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import *\n",
    "parseSchema = StructType((\n",
    "    StructField('InvoiceNo', StringType(), True),\n",
    "    StructField('Description', StringType(), True)\n",
    "))\n",
    "\n",
    "df.selectExpr(\"(InvoiceNo, Description) as struct\")\\\n",
    "    .select(to_json('struct').alias('newjson'), 'struct')\\\n",
    "    .select(from_json('newjson', parseSchema).alias('new'), 'newjson', 'struct').show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|num|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 用户自定义函数\n",
    "udfExampleDF = my_spark.range(5).toDF('num')\n",
    "udfExampleDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def power3(double_value):\n",
    "    return double_value ** 3\n",
    "\n",
    "power3(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|power3(num)|\n",
      "+-----------+\n",
      "|          0|\n",
      "|          1|\n",
      "+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "power3udf = udf(power3)\n",
    "udfExampleDF.select(power3udf(col('num'))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|POWER(num, 3)|\n",
      "+-------------+\n",
      "|          0.0|\n",
      "|          1.0|\n",
      "|          8.0|\n",
      "+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "udfExampleDF.select(power3(col('num'))).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|power3py(num)|\n",
      "+-------------+\n",
      "|         null|\n",
      "|         null|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 如上的写法只能在df中作为函数操作，但是不能写入expr之中\n",
    "#udfExampleDF.selectExpr(\"power3udf(num)\").show(2)\n",
    "my_spark.udf.register('power3py', power3, DoubleType())\n",
    "udfExampleDF.selectExpr('power3py(num)').show(2)  # 因为数据类型不对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|power3py(num)|\n",
      "+-------------+\n",
      "|            0|\n",
      "|            1|\n",
      "|            8|\n",
      "+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_spark.udf.register('power3py', power3, IntegerType())\n",
    "udfExampleDF.selectExpr('power3py(num)').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chapter 7 Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: string, UnitPrice: double, CustomerID: int, Country: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取retail data\n",
    "retail = my_spark.read.format('csv')\\\n",
    "    .option('header', 'True')\\\n",
    "    .option('inferSchema', 'True')\\\n",
    "    .load('/Users/yanghao/github/data/retail-data/retail.csv')\\\n",
    "    .coalesce(5)\n",
    "\n",
    "retail.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count, actuion not transformation\n",
    "retail.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|count(StockCode)|\n",
      "+----------------+\n",
      "|          541909|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, countDistinct, max, min, last, first, approx_count_distinct\n",
    "retail.select(count(\"StockCode\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT StockCode)|\n",
      "+-------------------------+\n",
      "|                     4070|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.select(countDistinct('StockCode')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            3364|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.select(approx_count_distinct('StockCode', 0.1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            2944|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.select(approx_count_distinct('StockCode', 0.2)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+-------------+-------------+\n",
      "|first(StockCode, false)|last(StockCode, false)|min(Quantity)|max(quantity)|\n",
      "+-----------------------+----------------------+-------------+-------------+\n",
      "|                 85123A|                 22138|       -80995|        80995|\n",
      "+-----------------------+----------------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.select(first('StockCode'), last('StockCode'), min('Quantity'), max('quantity')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail = retail.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    sum(UnitPrice)|\n",
      "+------------------+\n",
      "|1407819.9640006402|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.selectExpr(\"sum(UnitPrice)\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------------+-------------------+------------------+\n",
      "|stddev_samp(UnitPrice)|stddev_pop(UnitPrice)|var_samp(UnitPrice)|var_pop(UnitPrice)|\n",
      "+----------------------+---------------------+-------------------+------------------+\n",
      "|     69.31516172321436|     69.3150765336085|   4804.59164471536| 4804.579834860004|\n",
      "+----------------------+---------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 默认是样本误差和样本方差，需要使用总体误差和总体方差的时候\n",
    "from pyspark.sql.functions import sum, avg, mean, var_samp, stddev, stddev_pop, var_pop\n",
    "retail.select(stddev('UnitPrice'), stddev_pop('UnitPrice'), var_samp('UnitPrice'), var_pop('UnitPrice')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|skewness(Quantity)|kurtosis(Quantity)|\n",
      "+------------------+------------------+\n",
      "| 5.961063656227315|45.427546455787805|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 偏度和峰度\n",
    "from pyspark.sql.functions import skewness, kurtosis\n",
    "df.select(skewness('Quantity'), kurtosis('Quantity')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|corr(InvoiceNo, Quantity)|covar_samp(InvoiceNo, Quantity)|covar_pop(InvoiceNo, Quantity)|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|     0.023626982044350844|              11.27281460267257|             11.24042145726259|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr, covar_pop, covar_samp\n",
    "df.select(corr('InvoiceNo', 'Quantity'), covar_samp('InvoiceNo', 'Quantity'), covar_pop('InvoiceNo', 'Quantity')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+\n",
      "|collect_list(Country)|collect_set(Country)|\n",
      "+---------------------+--------------------+\n",
      "| [United Kingdom, ...|[Portugal, Italy,...|\n",
      "+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, collect_set\n",
    "retail.agg(collect_list('Country'), collect_set('Country')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+\n",
      "|collect_list(Country)|collect_set(Country)|\n",
      "+---------------------+--------------------+\n",
      "| [United Kingdom, ...|[Portugal, Italy,...|\n",
      "+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.select(collect_list('Country'), collect_set('Country')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+\n",
      "|InvoiceNo|CustomerID|count|\n",
      "+---------+----------+-----+\n",
      "|   536846|     14573|   76|\n",
      "|   537026|     12395|   12|\n",
      "|   537883|     14437|    5|\n",
      "|   538068|     17978|   12|\n",
      "|   538279|     14952|    7|\n",
      "|   538800|     16458|   10|\n",
      "|   538942|     17346|   12|\n",
      "|  C539947|     13854|    1|\n",
      "|   540096|     13253|   16|\n",
      "|   540530|     14755|   27|\n",
      "|   541225|     14099|   19|\n",
      "|   541978|     13551|    4|\n",
      "|   542093|     17677|   16|\n",
      "|   543188|     12567|   63|\n",
      "|   543590|     17377|   19|\n",
      "|  C543757|     13115|    1|\n",
      "|  C544318|     12989|    1|\n",
      "|   544578|     12365|    1|\n",
      "|   545165|     16339|   20|\n",
      "|   545289|     14732|   30|\n",
      "+---------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 先group，再aggregate\n",
    "retail.groupby('InvoiceNo', 'CustomerID').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+\n",
      "|InvoiceNo|CustomerID|count_quantity|\n",
      "+---------+----------+--------------+\n",
      "|   536846|     14573|            76|\n",
      "|   537026|     12395|            12|\n",
      "+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.groupby('InvoiceNo', 'CustomerID').agg(count('Quantity').alias('count_quantity')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+-------------------+\n",
      "|InvoiceNo|CustomerID|count_quantity|count_quantity_expr|\n",
      "+---------+----------+--------------+-------------------+\n",
      "|   536846|     14573|            76|                 76|\n",
      "|   537026|     12395|            12|                 12|\n",
      "+---------+----------+--------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.groupby('InvoiceNo', 'CustomerID').\\\n",
    "    agg(count('Quantity').alias('count_quantity'),\n",
    "       expr('count(Quantity) as count_quantity_expr'))\\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+--------------------+\n",
      "|InvoiceNo|     avg(Quantity)|stddev_pop(Quantity)|\n",
      "+---------+------------------+--------------------+\n",
      "|   536938|33.142857142857146|  20.698023172885524|\n",
      "|   537691|              8.15|   5.597097462078001|\n",
      "+---------+------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 利用map指定对不同列进行不同的aggregate\n",
    "retail.groupby('InvoiceNo').agg(expr('avg(Quantity)'), expr('stddev_pop(Quantity)')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|      date|   InvoiceDate|\n",
      "+----------+--------------+\n",
      "|2010-12-01|12/1/2010 8:26|\n",
      "|2010-12-01|12/1/2010 8:26|\n",
      "+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# window function 窗口函数\n",
    "from pyspark.sql.functions import col, to_date\n",
    "retail = retail.withColumn('date', to_date(col('InvoiceDate'), 'MM/d/yyyy H:mm'))\n",
    "retail.select('date', 'InvoiceDate').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+------------+\n",
      "|CustomerID|      date|Quantity|QuantityRank|\n",
      "+----------+----------+--------+------------+\n",
      "|     12346|2011-01-18|   74215|           1|\n",
      "|     12346|2011-01-18|  -74215|           2|\n",
      "|     12347|2010-12-07|      36|           1|\n",
      "|     12347|2010-12-07|      30|           2|\n",
      "|     12347|2010-12-07|      24|           3|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|      12|           4|\n",
      "|     12347|2010-12-07|       6|           5|\n",
      "|     12347|2010-12-07|       6|           5|\n",
      "+----------+----------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dense_rank, rank\n",
    "maxPurchaseQuantity = max(col(\"Quantity\")).over(windowSpec)\n",
    "purchaserank = dense_rank().over(windowSpec)\n",
    "\n",
    "retail.where('CustomerId is not null').orderBy('CustomerId')\\\n",
    "    .select(\n",
    "        col('CustomerID'),\n",
    "        col('date'),\n",
    "        col('Quantity'),\n",
    "        purchaserank.alias('QuantityRank')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+\n",
      "|      Date|       Country|total_quantity|\n",
      "+----------+--------------+--------------+\n",
      "|      null|          null|       4906888|\n",
      "|2010-12-01|United Kingdom|         21167|\n",
      "|2010-12-01|     Australia|           107|\n",
      "|2010-12-01|          EIRE|           243|\n",
      "|2010-12-01|        Norway|          1852|\n",
      "|2010-12-01|          null|         24032|\n",
      "|2010-12-01|        France|           449|\n",
      "|2010-12-01|   Netherlands|            97|\n",
      "|2010-12-01|       Germany|           117|\n",
      "|2010-12-02|       Germany|           146|\n",
      "|2010-12-02|          EIRE|             4|\n",
      "|2010-12-02|          null|         20855|\n",
      "|2010-12-02|United Kingdom|         20705|\n",
      "|2010-12-03|      Portugal|            65|\n",
      "|2010-12-03|   Switzerland|           110|\n",
      "|2010-12-03|          EIRE|          2375|\n",
      "|2010-12-03|        Poland|           140|\n",
      "|2010-12-03|         Spain|           400|\n",
      "|2010-12-03|        France|           239|\n",
      "|2010-12-03|          null|         11548|\n",
      "+----------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.rollup('Date', 'Country').agg(sum('Quantity'))\\\n",
    "    .selectExpr('Date', 'Country', '`sum(Quantity)` as total_quantity')\\\n",
    "    .orderBy('Date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+\n",
      "|      Date|       Country|total_quantity|\n",
      "+----------+--------------+--------------+\n",
      "|2010-12-01|        Norway|          1852|\n",
      "|2010-12-01|United Kingdom|         21167|\n",
      "|2010-12-01|       Germany|           117|\n",
      "|2010-12-01|     Australia|           107|\n",
      "|2010-12-01|   Netherlands|            97|\n",
      "|2010-12-01|          EIRE|           243|\n",
      "|2010-12-01|        France|           449|\n",
      "|2010-12-02|          EIRE|             4|\n",
      "|2010-12-02|       Germany|           146|\n",
      "|2010-12-02|United Kingdom|         20705|\n",
      "|2010-12-03|          EIRE|          2375|\n",
      "|2010-12-03|       Germany|           170|\n",
      "|2010-12-03|   Switzerland|           110|\n",
      "|2010-12-03|       Belgium|           528|\n",
      "|2010-12-03|        France|           239|\n",
      "|2010-12-03|         Italy|           164|\n",
      "|2010-12-03|United Kingdom|          7357|\n",
      "|2010-12-03|         Spain|           400|\n",
      "|2010-12-03|      Portugal|            65|\n",
      "|2010-12-03|        Poland|           140|\n",
      "+----------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail.groupby('Date', 'Country').agg(sum('Quantity'))\\\n",
    "    .selectExpr('Date', 'Country', '`sum(Quantity)` as total_quantity')\\\n",
    "    .orderBy('Date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------------+\n",
      "|Date|             Country|sum(Quantity)|\n",
      "+----+--------------------+-------------+\n",
      "|null|               Japan|        25218|\n",
      "|null|               Italy|         7999|\n",
      "|null|                 RSA|          352|\n",
      "|null|                null|      4906888|\n",
      "|null|            Portugal|        16044|\n",
      "|null|             Germany|       117448|\n",
      "|null|             Finland|        10666|\n",
      "|null|           Singapore|         5234|\n",
      "|null|              Cyprus|         6317|\n",
      "|null|           Australia|        83653|\n",
      "|null|  European Community|          497|\n",
      "|null|             Lebanon|          386|\n",
      "|null|         Unspecified|         1789|\n",
      "|null|               Spain|        26824|\n",
      "|null|                 USA|         1034|\n",
      "|null|     Channel Islands|         9479|\n",
      "|null|              Norway|        19247|\n",
      "|null|             Denmark|         8188|\n",
      "|null|United Arab Emirates|          982|\n",
      "|null|      Czech Republic|          592|\n",
      "+----+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cube\n",
    "from pyspark.sql.functions import sum\n",
    "retail.cube('Date', 'Country').agg(sum(col('Quantity')))\\\n",
    "    .select('Date', 'Country', 'sum(Quantity)').orderBy('Date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- Australia: long (nullable = true)\n",
      " |-- Austria: long (nullable = true)\n",
      " |-- Bahrain: long (nullable = true)\n",
      " |-- Belgium: long (nullable = true)\n",
      " |-- Brazil: long (nullable = true)\n",
      " |-- Canada: long (nullable = true)\n",
      " |-- Channel Islands: long (nullable = true)\n",
      " |-- Cyprus: long (nullable = true)\n",
      " |-- Czech Republic: long (nullable = true)\n",
      " |-- Denmark: long (nullable = true)\n",
      " |-- EIRE: long (nullable = true)\n",
      " |-- European Community: long (nullable = true)\n",
      " |-- Finland: long (nullable = true)\n",
      " |-- France: long (nullable = true)\n",
      " |-- Germany: long (nullable = true)\n",
      " |-- Greece: long (nullable = true)\n",
      " |-- Iceland: long (nullable = true)\n",
      " |-- Israel: long (nullable = true)\n",
      " |-- Italy: long (nullable = true)\n",
      " |-- Japan: long (nullable = true)\n",
      " |-- Lebanon: long (nullable = true)\n",
      " |-- Lithuania: long (nullable = true)\n",
      " |-- Malta: long (nullable = true)\n",
      " |-- Netherlands: long (nullable = true)\n",
      " |-- Norway: long (nullable = true)\n",
      " |-- Poland: long (nullable = true)\n",
      " |-- Portugal: long (nullable = true)\n",
      " |-- RSA: long (nullable = true)\n",
      " |-- Saudi Arabia: long (nullable = true)\n",
      " |-- Singapore: long (nullable = true)\n",
      " |-- Spain: long (nullable = true)\n",
      " |-- Sweden: long (nullable = true)\n",
      " |-- Switzerland: long (nullable = true)\n",
      " |-- USA: long (nullable = true)\n",
      " |-- United Arab Emirates: long (nullable = true)\n",
      " |-- United Kingdom: long (nullable = true)\n",
      " |-- Unspecified: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pivot\n",
    "pivoted = retail.na.drop().groupBy('date').pivot('Country').sum('Quantity')\n",
    "pivoted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+-------+-------+------+------+---------------+------+--------------+-------+----+------------------+-------+------+-------+------+-------+------+-----+-----+-------+---------+-----+-----------+------+------+--------+----+------------+---------+-----+------+-----------+----+--------------------+--------------+-----------+\n",
      "|      date|Australia|Austria|Bahrain|Belgium|Brazil|Canada|Channel Islands|Cyprus|Czech Republic|Denmark|EIRE|European Community|Finland|France|Germany|Greece|Iceland|Israel|Italy|Japan|Lebanon|Lithuania|Malta|Netherlands|Norway|Poland|Portugal| RSA|Saudi Arabia|Singapore|Spain|Sweden|Switzerland| USA|United Arab Emirates|United Kingdom|Unspecified|\n",
      "+----------+---------+-------+-------+-------+------+------+---------------+------+--------------+-------+----+------------------+-------+------+-------+------+-------+------+-----+-----+-------+---------+-----+-----------+------+------+--------+----+------------+---------+-----+------+-----------+----+--------------------+--------------+-----------+\n",
      "|2011-10-07|     null|   null|   null|   null|  null|  null|           null|   345|           325|    637| 448|              null|   null|   527|   2053|  null|   null|  null| null| null|   null|     null| null|        212|  null|  null|    null|null|        null|     null|  227|  null|       null|null|                null|         24771|       null|\n",
      "|2011-05-06|     null|     42|   null|    182|  null|  null|           null|  null|          null|   null|1694|              null|   null|  null|    222|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null|   88|  null|       null|null|                null|         15936|       null|\n",
      "|2011-01-30|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null|null|              null|   null|  null|   null|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null| null|  null|       null|null|                null|          3367|       null|\n",
      "|2011-11-18|     null|   null|   null|    315|  null|  null|           null|   300|           -40|   null| 263|              null|   null|   550|    491|  null|   null|  null|  544| null|   null|     null| null|         34|   242|    -8|    null|null|        null|     null| null|    -3|        669|null|                null|         16635|       null|\n",
      "|2011-07-18|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null|1202|              null|   null|   921|   null|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     2160| null|  null|       null|null|                null|          7795|       null|\n",
      "|2011-08-21|     null|   null|   null|   null|  null|  null|            800|  null|          null|   null| 148|              null|   null|   270|    187|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null|    1|  null|       null|null|                null|          6752|       null|\n",
      "|2011-01-23|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null|null|              null|   null|   126|   null|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null| null|  null|       null|null|                null|          5068|       null|\n",
      "|2011-07-07|     null|   null|   null|    143|  null|  null|           null|  null|          null|   null|null|              null|   null|  null|    550|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null|  216|  null|       null|null|                null|         15948|       null|\n",
      "|2010-12-15|     null|    -48|   null|   null|  null|  null|           null|  null|          null|   null|null|              null|   null|   134|    -12|  null|   null|   -56| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null| null|  null|       null|null|                null|         18151|       null|\n",
      "|2011-11-14|     null|    342|   null|   null|  null|  null|           null|  null|          null|   null| 206|              null|    150|   894|    212|  null|   null|  null|  -22| null|   null|     null| null|       null|  null|  null|     225|null|        null|     null| null|  1060|       null|null|                null|         28908|       null|\n",
      "|2010-12-01|      107|   null|   null|   null|  null|  null|           null|  null|          null|   null| 243|              null|   null|   449|    117|  null|   null|  null| null| null|   null|     null| null|         97|  1852|  null|    null|null|        null|     null| null|  null|       null|null|                null|         21167|       null|\n",
      "|2011-04-06|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null| 655|              null|   null|  null|    -14|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null| null|  null|       null|null|                null|          7358|       null|\n",
      "|2011-06-21|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null|  49|              null|   null|   351|    272|  null|   null|  null| null| null|   null|     null| null|        353|   582|  null|    null|null|        null|     null| null|  null|       null|null|                null|         11416|       null|\n",
      "|2011-02-21|     null|   null|   null|    194|  null|  null|           null|   173|          null|   null|null|              null|   null|   334|    789|  null|   null|  null| null| null|   null|     null| null|      12208|  null|  null|     454|null|        null|     null| null|  null|       null|null|                null|          6226|       null|\n",
      "|2011-09-04|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null|1272|              null|   null|   509|   1608|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null| null|  null|       null|null|                null|          7494|       null|\n",
      "|2011-08-30|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null| -87|              null|   null|  null|    133|  null|   null|  null| null| null|   null|     null|   -5|       null|  null|    49|    null|null|        null|     null| null|  null|       null|null|                null|          4003|       null|\n",
      "|2011-07-06|     null|   null|   null|    522|  null|  null|           null|  null|          null|   null|null|              null|   null|   597|   null|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null|  167|  3242|       null|null|                null|         13240|       null|\n",
      "|2011-04-27|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null| 163|              null|   null|    -2|    468|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null| null|   109|       null|null|                null|         16889|       null|\n",
      "|2011-10-23|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null|null|              null|   null|  null|     -2|  null|   null|  null| null| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null| null|  null|       null|null|                null|          7070|       null|\n",
      "|2011-08-05|     null|   null|   null|   null|  null|  null|           null|  null|          null|   null| 744|              null|   null|   486|    553|  null|   null|  null|  457| null|   null|     null| null|       null|  null|  null|    null|null|        null|     null| null|  null|       null|null|                null|          9948|       null|\n",
      "+----------+---------+-------+-------+-------+------+------+---------------+------+--------------+-------+----+------------------+-------+------+-------+------+-------+------+-----+-----+-------+---------+-----+-----------+------+------+--------+----+------------+---------+-----+------+-----------+----+--------------------+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|      date|Australia| USA|\n",
      "+----------+---------+----+\n",
      "|2011-12-06|     null|null|\n",
      "|2011-12-09|     null|null|\n",
      "|2011-12-08|     null|-196|\n",
      "|2011-12-07|     null|null|\n",
      "+----------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted.where(\"date > '2011-12-05'\").select('date', 'Australia', 'USA').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf aggregation\n",
    "# only in scala "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+\n",
      "| id|            name|graduate_program|   spark_status|\n",
      "+---+----------------+----------------+---------------+\n",
      "|  0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|\n",
      "+---+----------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person = my_spark.createDataFrame([\n",
    "    (0, \"Bill Chambers\", 0, [100]),\n",
    "    (1, \"Matei Zaharia\", 1, [500, 250, 100]),\n",
    "    (2, \"Michael Armbrust\", 1, [250, 100])\n",
    "]).toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")\n",
    "person.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "graduateProgram = my_spark.createDataFrame([\n",
    "    (0, \"Masters\", \"School of Information\", \"UC Berkeley\"),\n",
    "    (2, \"Masters\", \"EECS\", \"UC Berkeley\"),\n",
    "    (1, \"Ph.D\", \"EECS\", \"UC Berkeley\")\n",
    "]).toDF(\"id\", \"degree\", \"department\", \"school\")\n",
    "\n",
    "sparkstatus = my_spark.createDataFrame([\n",
    "    (500, \"Vice President\"),\n",
    "    (250, \"PMC Member\"),\n",
    "    (100, \"Contributor\")\n",
    "]).toDF('id', 'status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|Masters|                EECS|UC Berkeley|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|        status|\n",
      "+---+--------------+\n",
      "|500|Vice President|\n",
      "|250|    PMC Member|\n",
      "|100|   Contributor|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkstatus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'(graduate_program = id)'>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# innner join default\n",
    "joinExpr = person[\"graduate_program\"] == graduateProgram[\"id\"]\n",
    "joinExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(graduateProgram, joinExpr, 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|   1|   Matei Zaharia|               1|[500, 250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|   2|Michael Armbrust|               1|     [250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|null|            null|            null|           null|  2|Masters|                EECS|UC Berkeley|\n",
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(graduateProgram, joinExpr, 'outer').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+----+----------------+----------------+---------------+\n",
      "| id| degree|          department|     school|  id|            name|graduate_program|   spark_status|\n",
      "+---+-------+--------------------+-----------+----+----------------+----------------+---------------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|   0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|   1|   Matei Zaharia|               1|[500, 250, 100]|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|   2|Michael Armbrust|               1|     [250, 100]|\n",
      "|  2|Masters|                EECS|UC Berkeley|null|            null|            null|           null|\n",
      "+---+-------+--------------------+-----------+----+----------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# left outer join\n",
    "graduateProgram.join(person, joinExpr, 'left_outer').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|   1|   Matei Zaharia|               1|[500, 250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|   2|Michael Armbrust|               1|     [250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|null|            null|            null|           null|  2|Masters|                EECS|UC Berkeley|\n",
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(graduateProgram, joinExpr, 'right_outer').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.join(person, joinExpr, 'left_semi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+-----------+\n",
      "| id| degree|department|     school|\n",
      "+---+-------+----------+-----------+\n",
      "|  2|Masters|      EECS|UC Berkeley|\n",
      "+---+-------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.join(person, joinExpr, 'left_anti').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  0|   Bill Chambers|               0|          [100]|  2|Masters|                EECS|UC Berkeley|\n",
      "|  0|   Bill Chambers|               0|          [100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  2|Masters|                EECS|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  2|Masters|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.crossJoin(graduateProgram).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------------+---------------+---+--------------+\n",
      "|personID|            name|graduate_program|   spark_status| id|        status|\n",
      "+--------+----------------+----------------+---------------+---+--------------+\n",
      "|       0|   Bill Chambers|               0|          [100]|100|   Contributor|\n",
      "|       1|   Matei Zaharia|               1|[500, 250, 100]|500|Vice President|\n",
      "|       1|   Matei Zaharia|               1|[500, 250, 100]|250|    PMC Member|\n",
      "|       1|   Matei Zaharia|               1|[500, 250, 100]|100|   Contributor|\n",
      "|       2|Michael Armbrust|               1|     [250, 100]|250|    PMC Member|\n",
      "|       2|Michael Armbrust|               1|     [250, 100]|100|   Contributor|\n",
      "+--------+----------------+----------------+---------------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# joins on complec types\n",
    "from pyspark.sql.functions import expr\n",
    "person.withColumnRenamed(\"id\", \"personID\")\\\n",
    "    .join(sparkstatus, expr(\"array_contains(spark_status, id)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+\n",
      "| id|            name|graduate_program|   spark_status|\n",
      "+---+----------------+----------------+---------------+\n",
      "|  0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|\n",
      "+---+----------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|Masters|                EECS|UC Berkeley|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join之后列名重复的问题\n",
    "graduateProgram.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='test_pandas', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.createTempView(\"test_pandas\")\n",
    "my_spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|new|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|  2|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|  2|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_spark.sql(\"select * from test_pandas limit 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = my_spark.sql(\"select UnitPrice+1 as test from test_pandas limit 2\")\n",
    "type(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     test|\n",
      "+---------+\n",
      "|     3.55|\n",
      "|4.3900003|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|   col_name|data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|  InvoiceNo|   bigint|   null|\n",
      "|  StockCode|   string|   null|\n",
      "|Description|   string|   null|\n",
      "|   Quantity|      int|   null|\n",
      "|InvoiceDate|timestamp|   null|\n",
      "|  UnitPrice|    float|   null|\n",
      "| CustomerID|    float|   null|\n",
      "|    Country|   string|   null|\n",
      "|        new|      int|   null|\n",
      "+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_spark.sql(\"DESCRIBE TABLE test_pandas\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = my_spark.read.csv('./2010-12-01.csv', sep='\\t', header=True, inferSchema=True)\n",
    "df.show(2, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN               |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = my_spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"sep\", \"\\t\")\\\n",
    "    .option(\"inferSchema\",\"true\")\\\n",
    "    .load('./2010-12-01.csv')\n",
    "df2.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN               |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 多个option写在一起\n",
    "df3 = my_spark.read.format(\"csv\")\\\n",
    "    .options(header=True, sep='\\t', inferSchema=True)\\\n",
    "    .load('./2010-12-01.csv')\n",
    "df3.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "df2.select(\"Quantity\", \"Country\")\\\n",
    "    .write.format(\"csv\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option(\"sep\", \"\\t\")\\\n",
    "    .save(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-12-01.csv         Pandas udf.ipynb       基本操作.ipynb\n",
      "Low-level APIs.ipynb   \u001b[1m\u001b[36mspark-warehouse\u001b[m\u001b[m\n",
      "Machine Learning.ipynb \u001b[1m\u001b[36mtest.csv\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat_ws\n",
    "new_df = df.select('*',\n",
    "                   concat_ws(\"-\", col('InvoiceNo'), col(\"StockCode\"), col(\"Quantity\")).alias(\"新的列\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|         新的列|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|536365-85123A-6|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom| 536365-71053-6|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|新的列         |\n",
      "+---------------+\n",
      "|536365-85123A-6|\n",
      "|536365-71053-6 |\n",
      "+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.select(\"新的列\").show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SET 7 BABUSHKA NESTING BOXES</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>7.65</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GLASS STAR FROSTED T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HAND WARMER UNION JACK</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:28:00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAND WARMER RED POLKA DOT</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:28:00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASSORTED COLOUR BIRD ORNAMENT</td>\n",
       "      <td>32</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>1.69</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>POPPY'S PLAYHOUSE BEDROOM</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>POPPY'S PLAYHOUSE KITCHEN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FELTCRAFT PRINCESS CHARLOTTE DOLL</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IVORY KNITTED MUG COSY</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>1.65</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BOX OF 6 ASSORTED COLOUR TEASPOONS</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BOX OF VINTAGE JIGSAW BLOCKS</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BOX OF VINTAGE ALPHABET BLOCKS</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HOME BUILDING BLOCK WORD</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>5.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LOVE BUILDING BLOCK WORD</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>5.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RECIPE BOX WITH METAL HEART</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>7.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DOORMAT NEW ENGLAND</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>7.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>JAM MAKING SET WITH JARS</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RED COAT RACK PARIS FASHION</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>YELLOW COAT RACK PARIS FASHION</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BLUE COAT RACK PARIS FASHION</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BATH BUILDING BLOCK WORD</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 08:35:00</td>\n",
       "      <td>5.95</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ALARM CLOCK BAKELIKE PINK</td>\n",
       "      <td>24</td>\n",
       "      <td>2010-12-01 08:45:00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>12583.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ALARM CLOCK BAKELIKE RED</td>\n",
       "      <td>24</td>\n",
       "      <td>2010-12-01 08:45:00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>12583.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ALARM CLOCK BAKELIKE GREEN</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12-01 08:45:00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>12583.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PANDA AND BUNNIES STICKER SHEET</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12-01 08:45:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12583.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>JAM MAKING SET PRINTED</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.45</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>LAVENDER INCENSE IN TIN</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>TV DINNER TRAY VINTAGE PAISLEY</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>SET OF 4 ENGLISH ROSE PLACEMATS</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>SET OF 4 ENGLISH ROSE COASTERS</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>TRIPLE PHOTO FRAME CORNICE</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>FAMILY PHOTO FRAME CORNICE</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>MIRRORED DISCO BALL</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>5.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>DISCO BALL ROTATOR BATTERY OPERATED</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>SILVER LOOKING MIRROR</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>LADIES &amp; GENTLEMEN METAL SIGN</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>METAL SIGN HER DINNER IS SERVED</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>2.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>YOU'RE CONFUSING ME METAL SIGN</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.69</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>DOORMAT TOPIARY</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>7.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>BATHROOM METAL SIGN</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>KITCHEN METAL SIGN</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>TOILET METAL SIGN</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>METAL SIGN TAKE IT OR LEAVE IT</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>2.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>I'M ON HOLIDAY METAL SIGN</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>GROW YOUR OWN BASIL IN ENAMEL MUG</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>SET/10 PINK POLKADOT PARTY CANDLES</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>SET 20 NAPKINS FAIRY CAKES DESIGN</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>60 TEATIME FAIRY CAKE CASES</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>SET OF 6 T-LIGHTS SNOWMEN</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>2.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>SET OF 6 T-LIGHTS SANTA</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>2.95</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>SET OF 9 HEART SHAPED BALLOONS</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>SANDWICH BATH SPONGE</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>APPLE BATH SPONGE</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>STRAWBERRY BATH SPONGE</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>BLACK PIRATE TREASURE CHEST</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 11:21:00</td>\n",
       "      <td>1.65</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Description  Quantity         InvoiceDate  \\\n",
       "0     WHITE HANGING HEART T-LIGHT HOLDER         6 2010-12-01 08:26:00   \n",
       "1                    WHITE METAL LANTERN         6 2010-12-01 08:26:00   \n",
       "2         CREAM CUPID HEARTS COAT HANGER         8 2010-12-01 08:26:00   \n",
       "3    KNITTED UNION FLAG HOT WATER BOTTLE         6 2010-12-01 08:26:00   \n",
       "4         RED WOOLLY HOTTIE WHITE HEART.         6 2010-12-01 08:26:00   \n",
       "5           SET 7 BABUSHKA NESTING BOXES         2 2010-12-01 08:26:00   \n",
       "6      GLASS STAR FROSTED T-LIGHT HOLDER         6 2010-12-01 08:26:00   \n",
       "7                 HAND WARMER UNION JACK         6 2010-12-01 08:28:00   \n",
       "8              HAND WARMER RED POLKA DOT         6 2010-12-01 08:28:00   \n",
       "9          ASSORTED COLOUR BIRD ORNAMENT        32 2010-12-01 08:34:00   \n",
       "10             POPPY'S PLAYHOUSE BEDROOM         6 2010-12-01 08:34:00   \n",
       "11             POPPY'S PLAYHOUSE KITCHEN         6 2010-12-01 08:34:00   \n",
       "12     FELTCRAFT PRINCESS CHARLOTTE DOLL         8 2010-12-01 08:34:00   \n",
       "13                IVORY KNITTED MUG COSY         6 2010-12-01 08:34:00   \n",
       "14    BOX OF 6 ASSORTED COLOUR TEASPOONS         6 2010-12-01 08:34:00   \n",
       "15          BOX OF VINTAGE JIGSAW BLOCKS         3 2010-12-01 08:34:00   \n",
       "16        BOX OF VINTAGE ALPHABET BLOCKS         2 2010-12-01 08:34:00   \n",
       "17              HOME BUILDING BLOCK WORD         3 2010-12-01 08:34:00   \n",
       "18              LOVE BUILDING BLOCK WORD         3 2010-12-01 08:34:00   \n",
       "19           RECIPE BOX WITH METAL HEART         4 2010-12-01 08:34:00   \n",
       "20                   DOORMAT NEW ENGLAND         4 2010-12-01 08:34:00   \n",
       "21              JAM MAKING SET WITH JARS         6 2010-12-01 08:34:00   \n",
       "22           RED COAT RACK PARIS FASHION         3 2010-12-01 08:34:00   \n",
       "23        YELLOW COAT RACK PARIS FASHION         3 2010-12-01 08:34:00   \n",
       "24          BLUE COAT RACK PARIS FASHION         3 2010-12-01 08:34:00   \n",
       "25              BATH BUILDING BLOCK WORD         3 2010-12-01 08:35:00   \n",
       "26             ALARM CLOCK BAKELIKE PINK        24 2010-12-01 08:45:00   \n",
       "27              ALARM CLOCK BAKELIKE RED        24 2010-12-01 08:45:00   \n",
       "28            ALARM CLOCK BAKELIKE GREEN        12 2010-12-01 08:45:00   \n",
       "29       PANDA AND BUNNIES STICKER SHEET        12 2010-12-01 08:45:00   \n",
       "..                                   ...       ...                 ...   \n",
       "327               JAM MAKING SET PRINTED         4 2010-12-01 11:21:00   \n",
       "328              LAVENDER INCENSE IN TIN         1 2010-12-01 11:21:00   \n",
       "329       TV DINNER TRAY VINTAGE PAISLEY         1 2010-12-01 11:21:00   \n",
       "330      SET OF 4 ENGLISH ROSE PLACEMATS         2 2010-12-01 11:21:00   \n",
       "331       SET OF 4 ENGLISH ROSE COASTERS         2 2010-12-01 11:21:00   \n",
       "332           TRIPLE PHOTO FRAME CORNICE         2 2010-12-01 11:21:00   \n",
       "333           FAMILY PHOTO FRAME CORNICE         1 2010-12-01 11:21:00   \n",
       "334                  MIRRORED DISCO BALL         1 2010-12-01 11:21:00   \n",
       "335  DISCO BALL ROTATOR BATTERY OPERATED         1 2010-12-01 11:21:00   \n",
       "336                SILVER LOOKING MIRROR         3 2010-12-01 11:21:00   \n",
       "337        LADIES & GENTLEMEN METAL SIGN         1 2010-12-01 11:21:00   \n",
       "338      METAL SIGN HER DINNER IS SERVED         1 2010-12-01 11:21:00   \n",
       "339       YOU'RE CONFUSING ME METAL SIGN         2 2010-12-01 11:21:00   \n",
       "340                      DOORMAT TOPIARY         1 2010-12-01 11:21:00   \n",
       "341                  BATHROOM METAL SIGN         1 2010-12-01 11:21:00   \n",
       "342                   KITCHEN METAL SIGN         1 2010-12-01 11:21:00   \n",
       "343                    TOILET METAL SIGN         2 2010-12-01 11:21:00   \n",
       "344       METAL SIGN TAKE IT OR LEAVE IT         4 2010-12-01 11:21:00   \n",
       "345            I'M ON HOLIDAY METAL SIGN         2 2010-12-01 11:21:00   \n",
       "346    GROW YOUR OWN BASIL IN ENAMEL MUG         1 2010-12-01 11:21:00   \n",
       "347   SET/10 PINK POLKADOT PARTY CANDLES         1 2010-12-01 11:21:00   \n",
       "348    SET 20 NAPKINS FAIRY CAKES DESIGN         1 2010-12-01 11:21:00   \n",
       "349          60 TEATIME FAIRY CAKE CASES         3 2010-12-01 11:21:00   \n",
       "350            SET OF 6 T-LIGHTS SNOWMEN         1 2010-12-01 11:21:00   \n",
       "351              SET OF 6 T-LIGHTS SANTA         1 2010-12-01 11:21:00   \n",
       "352       SET OF 9 HEART SHAPED BALLOONS         2 2010-12-01 11:21:00   \n",
       "353                 SANDWICH BATH SPONGE         3 2010-12-01 11:21:00   \n",
       "354                    APPLE BATH SPONGE         1 2010-12-01 11:21:00   \n",
       "355               STRAWBERRY BATH SPONGE         1 2010-12-01 11:21:00   \n",
       "356          BLACK PIRATE TREASURE CHEST         2 2010-12-01 11:21:00   \n",
       "\n",
       "     UnitPrice  CustomerID         Country  \n",
       "0         2.55     17850.0  United Kingdom  \n",
       "1         3.39     17850.0  United Kingdom  \n",
       "2         2.75     17850.0  United Kingdom  \n",
       "3         3.39     17850.0  United Kingdom  \n",
       "4         3.39     17850.0  United Kingdom  \n",
       "5         7.65     17850.0  United Kingdom  \n",
       "6         4.25     17850.0  United Kingdom  \n",
       "7         1.85     17850.0  United Kingdom  \n",
       "8         1.85     17850.0  United Kingdom  \n",
       "9         1.69     13047.0  United Kingdom  \n",
       "10        2.10     13047.0  United Kingdom  \n",
       "11        2.10     13047.0  United Kingdom  \n",
       "12        3.75     13047.0  United Kingdom  \n",
       "13        1.65     13047.0  United Kingdom  \n",
       "14        4.25     13047.0  United Kingdom  \n",
       "15        4.95     13047.0  United Kingdom  \n",
       "16        9.95     13047.0  United Kingdom  \n",
       "17        5.95     13047.0  United Kingdom  \n",
       "18        5.95     13047.0  United Kingdom  \n",
       "19        7.95     13047.0  United Kingdom  \n",
       "20        7.95     13047.0  United Kingdom  \n",
       "21        4.25     13047.0  United Kingdom  \n",
       "22        4.95     13047.0  United Kingdom  \n",
       "23        4.95     13047.0  United Kingdom  \n",
       "24        4.95     13047.0  United Kingdom  \n",
       "25        5.95     13047.0  United Kingdom  \n",
       "26        3.75     12583.0          France  \n",
       "27        3.75     12583.0          France  \n",
       "28        3.75     12583.0          France  \n",
       "29        0.85     12583.0          France  \n",
       "..         ...         ...             ...  \n",
       "327       1.45     15862.0  United Kingdom  \n",
       "328       1.25     15862.0  United Kingdom  \n",
       "329       4.95     15862.0  United Kingdom  \n",
       "330       3.75     15862.0  United Kingdom  \n",
       "331       1.25     15862.0  United Kingdom  \n",
       "332       9.95     15862.0  United Kingdom  \n",
       "333       9.95     15862.0  United Kingdom  \n",
       "334       5.95     15862.0  United Kingdom  \n",
       "335       4.25     15862.0  United Kingdom  \n",
       "336       4.95     15862.0  United Kingdom  \n",
       "337       2.55     15862.0  United Kingdom  \n",
       "338       2.95     15862.0  United Kingdom  \n",
       "339       1.69     15862.0  United Kingdom  \n",
       "340       7.95     15862.0  United Kingdom  \n",
       "341       0.55     15862.0  United Kingdom  \n",
       "342       0.55     15862.0  United Kingdom  \n",
       "343       0.55     15862.0  United Kingdom  \n",
       "344       2.95     15862.0  United Kingdom  \n",
       "345       2.10     15862.0  United Kingdom  \n",
       "346       2.10     15862.0  United Kingdom  \n",
       "347       1.25     15862.0  United Kingdom  \n",
       "348       0.85     15862.0  United Kingdom  \n",
       "349       0.55     15862.0  United Kingdom  \n",
       "350       2.95     15862.0  United Kingdom  \n",
       "351       2.95     15862.0  United Kingdom  \n",
       "352       1.25     15862.0  United Kingdom  \n",
       "353       1.25     15862.0  United Kingdom  \n",
       "354       1.25     15862.0  United Kingdom  \n",
       "355       1.25     15862.0  United Kingdom  \n",
       "356       1.65     15862.0  United Kingdom  \n",
       "\n",
       "[357 rows x 6 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
