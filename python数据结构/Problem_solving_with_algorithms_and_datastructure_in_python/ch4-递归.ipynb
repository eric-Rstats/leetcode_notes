{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 递归\n",
    "\n",
    "## 递归的三定律\n",
    "\n",
    "+ 1. 递归算法必须具有基本情况\n",
    "+ 2. 递归算法必须改变其状态并向基本情况靠近\n",
    "+ 3. 递归算法必须以递归的方式调用自身\n",
    "\n",
    "## 将整数转换为任意进制字符串\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toStr(n, base):\n",
    "    converString = '0123456789ABCDEF'\n",
    "    if n < base:\n",
    "        return converString[n]\n",
    "    else:\n",
    "        return toStr(n//base, base) + converString[n%base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8F'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toStr(143, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 栈帧：实现递归\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个类实现stack的基本功能\n",
    "class Stack:\n",
    "    # 用列表来存储其中元素\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "        \n",
    "    def push(self, item):\n",
    "        self.items.append(item)\n",
    "        \n",
    "    def pop(self):\n",
    "        return self.items.pop()\n",
    "    \n",
    "    def peek(self):\n",
    "        return self.items[len(self.items) - 1]\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def isEmpty(self):\n",
    "        return len(self.items) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rStack = Stack()\n",
    "\n",
    "def toStr(n, base):\n",
    "    convertString = '0123456789ABCDEF'\n",
    "    while n > 0:\n",
    "        if n < base:\n",
    "            rStack.push(convertString[n])\n",
    "        else:\n",
    "            rStack.push(convertString[n % base])\n",
    "            \n",
    "        n = n // base\n",
    "        \n",
    "    res = ''\n",
    "    while not rStack.isEmpty():\n",
    "        res = res + str(rStack.pop())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5AD'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toStr(1453, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化递归\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTurtle = turtle.Turtle()\n",
    "myWin = turtle.Screen()\n",
    "\n",
    "def drawSpiral(myTurtle, lineLen):\n",
    "    if lineLen > 0:\n",
    "        myTurtle.forward(lineLen)\n",
    "        myTurtle.right(90)\n",
    "        drawSpiral(myTurtle,lineLen-5)\n",
    "\n",
    "drawSpiral(myTurtle,100)\n",
    "myWin.exitonclick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle\n",
    "\n",
    "def tree(branchLen,t):\n",
    "    if branchLen > 5:\n",
    "        t.forward(branchLen)\n",
    "        t.right(20)\n",
    "        tree(branchLen-15,t)\n",
    "        t.left(40)\n",
    "        tree(branchLen-15,t)\n",
    "        t.right(20)\n",
    "        t.backward(branchLen)\n",
    "\n",
    "def main():\n",
    "    t = turtle.Turtle()\n",
    "    myWin = turtle.Screen()\n",
    "    t.left(90)\n",
    "    t.up()\n",
    "    t.backward(100)\n",
    "    t.down()\n",
    "    t.color(\"green\")\n",
    "    tree(75,t)\n",
    "    myWin.exitonclick()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 谢尔宾斯基三角形\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle\n",
    "\n",
    "def drawTriangle(points,color,myTurtle):\n",
    "    myTurtle.fillcolor(color)\n",
    "    myTurtle.up()\n",
    "    myTurtle.goto(points[0][0],points[0][1])\n",
    "    myTurtle.down()\n",
    "    myTurtle.begin_fill()\n",
    "    myTurtle.goto(points[1][0],points[1][1])\n",
    "    myTurtle.goto(points[2][0],points[2][1])\n",
    "    myTurtle.goto(points[0][0],points[0][1])\n",
    "    myTurtle.end_fill()\n",
    "\n",
    "def getMid(p1,p2):\n",
    "    return ( (p1[0]+p2[0]) / 2, (p1[1] + p2[1]) / 2)\n",
    "\n",
    "def sierpinski(points,degree,myTurtle):\n",
    "    colormap = ['blue','red','green','white','yellow',\n",
    "                'violet','orange']\n",
    "    drawTriangle(points,colormap[degree],myTurtle)\n",
    "    if degree > 0:\n",
    "        sierpinski([points[0],\n",
    "                        getMid(points[0], points[1]),\n",
    "                        getMid(points[0], points[2])],\n",
    "                   degree-1, myTurtle)\n",
    "        sierpinski([points[1],\n",
    "                        getMid(points[0], points[1]),\n",
    "                        getMid(points[1], points[2])],\n",
    "                   degree-1, myTurtle)\n",
    "        sierpinski([points[2],\n",
    "                        getMid(points[2], points[1]),\n",
    "                        getMid(points[0], points[2])],\n",
    "                   degree-1, myTurtle)\n",
    "\n",
    "def main():\n",
    "   myTurtle = turtle.Turtle()\n",
    "   myWin = turtle.Screen()\n",
    "   myPoints = [[-100,-50],[0,100],[100,-50]]\n",
    "   sierpinski(myPoints,3,myTurtle)\n",
    "   myWin.exitonclick()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态规划\n",
    "\n",
    "\n",
    "![动态规划](https://facert.gitbooks.io/python-data-structure-cn/4.%E9%80%92%E5%BD%92/4.12.%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/assets/4.12.%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92.1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缓存技术"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recDC(coinValueList, change, knownResults):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    ______\n",
    "    coinValueList: 币种的面值列表\n",
    "    change:需要找零的总面值\n",
    "    knownResults:已知的找零面值需要的金币个数\n",
    "    \n",
    "    Returns:\n",
    "    _______\n",
    "    numcoins: 最小找零个数\n",
    "    \"\"\"\n",
    "    mincoins = change\n",
    "    if change in coinValueList:\n",
    "        # 如果需要找零的就是已知币，即只需要一个币\n",
    "        knownResults[change] = 1\n",
    "        return 1\n",
    "    elif knownResults[change] > 0:\n",
    "        # 如果之前存储过，就直接返回\n",
    "        return knownResults[change]\n",
    "    else:\n",
    "        # 否则需要计算实际需要多少个找零\n",
    "        for i in [c for c in coinValueList if c <= change]:\n",
    "            numcoins = 1 + recDC(coinValueList, change-i, knownResults)\n",
    "            \n",
    "            if numcoins < mincoins:\n",
    "                mincoins = numcoins\n",
    "                knownResults[change] = mincoins\n",
    "    return mincoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recDC([1,5,10,25],63,[0]*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  动态规划方式\n",
    "\n",
    "\n",
    "+ 一个一分钱加上 11-1 = 10分（1） 的最小硬币数\n",
    "+ 一个五分钱加上 11-5 = 6分（2）的最小硬币数\n",
    "+ 一个十分钱加上 11-10 = 1 分（1）最小硬币数\n",
    "\n",
    "选项 1 或 3 总共需要两个硬币，这是 11 美分的最小硬币数。\n",
    "\n",
    "![](https://facert.gitbooks.io/python-data-structure-cn/4.%E9%80%92%E5%BD%92/4.12.%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/assets/4.12.%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92.figure6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpMakeChange(coinValueList, change, minCoins):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    ______\n",
    "    coinValueList: 各种币值的列表\n",
    "    change:需要找零的总价格\n",
    "    minCoins:列表，存储了各种面值的最小找零个数;初始化的时候应该是都为0\n",
    "    \n",
    "    Returns:\n",
    "    _______\n",
    "    minCoins:列表，存储了各种面值的最小找零个数\n",
    "    \"\"\"\n",
    "    for cents in range(change + 1):\n",
    "        coinCounts = cents\n",
    "        for j in [c for c in coinValueList if c <= cents]:\n",
    "            if minCoins[cents-j]+1 < coinCounts:\n",
    "                # 如果一个已有的基础币j加上剩余的零钱需要的个数小于当前个数，那么说明当前个数不是最优\n",
    "                coinCounts = minCoins[cents-j]+1\n",
    "        minCoins[cents] = coinCounts\n",
    "    return minCoins[change]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpMakeChange([2,5,10], 35, [0]*36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述方法只返回最小找零个数，但是没有返回具体使用的找零币值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找零的面值为: 63 时需要:\n",
      "3 个硬币！\n",
      "分别为:\n",
      "21\n",
      "21\n",
      "21\n",
      "The Used list is as follows:\n",
      "[1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 10, 1, 1, 1, 1, 5, 1, 1, 1, 1, 10, 21, 1, 1, 1, 25, 1, 1, 1, 1, 5, 10, 1, 1, 1, 10, 1, 1, 1, 1, 5, 10, 21, 1, 1, 10, 21, 1, 1, 1, 25, 1, 10, 1, 1, 5, 10, 1, 1, 1, 10, 1, 10, 21]\n"
     ]
    }
   ],
   "source": [
    "def dpMakeChange(coinValueList, change, minCoins, coinsUsed):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    ______\n",
    "    coinValueList: 各种币值的列表\n",
    "    change:需要找零的总价格\n",
    "    minCoins:列表，存储了各种面值的最小找零个数;初始化的时候应该是都为0\n",
    "    coinsUsed:找零使用的币\n",
    "    \n",
    "    Returns:\n",
    "    _______\n",
    "    minCoins:列表，存储了各种面值的最小找零个数\n",
    "    \"\"\"\n",
    "    for cents in range(change+1):\n",
    "        coinCounts = cents\n",
    "        newCoin = 1\n",
    "        \n",
    "        for j in [c for c in coinValueList if c <= cents]:\n",
    "            if minCoins[cents-j] + 1 < coinCounts:\n",
    "                coinCounts = minCoins[cents-j]+1\n",
    "                newCoin = j\n",
    "        minCoins[cents] = coinCounts\n",
    "        coinsUsed[cents] = newCoin\n",
    "        \n",
    "    return minCoins[change]\n",
    "\n",
    "def printCoins(coinsUsed, change):\n",
    "    coin = change\n",
    "    while coin > 0:\n",
    "        thisCoin = coinsUsed[coin]\n",
    "        print(thisCoin)\n",
    "        coin = coin - thisCoin\n",
    "        \n",
    "def main():\n",
    "    amt = 63\n",
    "    clist = [1,5,10,21,25]\n",
    "    coinsUsed = [0]*(amt+1)\n",
    "    coinCount = [0]*(amt+1)\n",
    "    \n",
    "    print('找零的面值为:', amt, '时需要:')\n",
    "    print(dpMakeChange(clist, amt, coinCount, coinsUsed), '个硬币！')\n",
    "    print('分别为:')\n",
    "    printCoins(coinsUsed, amt)\n",
    "    print('The Used list is as follows:')\n",
    "    print(coinsUsed)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_impurity_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A decision tree classifier.\n",
       "\n",
       "Read more in the :ref:`User Guide <tree>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "criterion : string, optional (default=\"gini\")\n",
       "    The function to measure the quality of a split. Supported criteria are\n",
       "    \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
       "\n",
       "splitter : string, optional (default=\"best\")\n",
       "    The strategy used to choose the split at each node. Supported\n",
       "    strategies are \"best\" to choose the best split and \"random\" to choose\n",
       "    the best random split.\n",
       "\n",
       "max_depth : int or None, optional (default=None)\n",
       "    The maximum depth of the tree. If None, then nodes are expanded until\n",
       "    all leaves are pure or until all leaves contain less than\n",
       "    min_samples_split samples.\n",
       "\n",
       "min_samples_split : int, float, optional (default=2)\n",
       "    The minimum number of samples required to split an internal node:\n",
       "\n",
       "    - If int, then consider `min_samples_split` as the minimum number.\n",
       "    - If float, then `min_samples_split` is a percentage and\n",
       "      `ceil(min_samples_split * n_samples)` are the minimum\n",
       "      number of samples for each split.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for percentages.\n",
       "\n",
       "min_samples_leaf : int, float, optional (default=1)\n",
       "    The minimum number of samples required to be at a leaf node:\n",
       "\n",
       "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
       "    - If float, then `min_samples_leaf` is a percentage and\n",
       "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
       "      number of samples for each node.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for percentages.\n",
       "\n",
       "min_weight_fraction_leaf : float, optional (default=0.)\n",
       "    The minimum weighted fraction of the sum total of weights (of all\n",
       "    the input samples) required to be at a leaf node. Samples have\n",
       "    equal weight when sample_weight is not provided.\n",
       "\n",
       "max_features : int, float, string or None, optional (default=None)\n",
       "    The number of features to consider when looking for the best split:\n",
       "\n",
       "        - If int, then consider `max_features` features at each split.\n",
       "        - If float, then `max_features` is a percentage and\n",
       "          `int(max_features * n_features)` features are considered at each\n",
       "          split.\n",
       "        - If \"auto\", then `max_features=sqrt(n_features)`.\n",
       "        - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
       "        - If \"log2\", then `max_features=log2(n_features)`.\n",
       "        - If None, then `max_features=n_features`.\n",
       "\n",
       "    Note: the search for a split does not stop until at least one\n",
       "    valid partition of the node samples is found, even if it requires to\n",
       "    effectively inspect more than ``max_features`` features.\n",
       "\n",
       "random_state : int, RandomState instance or None, optional (default=None)\n",
       "    If int, random_state is the seed used by the random number generator;\n",
       "    If RandomState instance, random_state is the random number generator;\n",
       "    If None, the random number generator is the RandomState instance used\n",
       "    by `np.random`.\n",
       "\n",
       "max_leaf_nodes : int or None, optional (default=None)\n",
       "    Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
       "    Best nodes are defined as relative reduction in impurity.\n",
       "    If None then unlimited number of leaf nodes.\n",
       "\n",
       "min_impurity_decrease : float, optional (default=0.)\n",
       "    A node will be split if this split induces a decrease of the impurity\n",
       "    greater than or equal to this value.\n",
       "\n",
       "    The weighted impurity decrease equation is the following::\n",
       "\n",
       "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
       "                            - N_t_L / N_t * left_impurity)\n",
       "\n",
       "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
       "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
       "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
       "\n",
       "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
       "    if ``sample_weight`` is passed.\n",
       "\n",
       "    .. versionadded:: 0.19\n",
       "\n",
       "min_impurity_split : float,\n",
       "    Threshold for early stopping in tree growth. A node will split\n",
       "    if its impurity is above the threshold, otherwise it is a leaf.\n",
       "\n",
       "    .. deprecated:: 0.19\n",
       "       ``min_impurity_split`` has been deprecated in favor of\n",
       "       ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.\n",
       "       Use ``min_impurity_decrease`` instead.\n",
       "\n",
       "class_weight : dict, list of dicts, \"balanced\" or None, default=None\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    If not given, all classes are supposed to have weight one. For\n",
       "    multi-output problems, a list of dicts can be provided in the same\n",
       "    order as the columns of y.\n",
       "\n",
       "    Note that for multioutput (including multilabel) weights should be\n",
       "    defined for each class of every column in its own dict. For example,\n",
       "    for four-class multilabel classification weights should be\n",
       "    [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
       "    [{1:1}, {2:5}, {3:1}, {4:1}].\n",
       "\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``\n",
       "\n",
       "    For multi-output, the weights of each column of y will be multiplied.\n",
       "\n",
       "    Note that these weights will be multiplied with sample_weight (passed\n",
       "    through the fit method) if sample_weight is specified.\n",
       "\n",
       "presort : bool, optional (default=False)\n",
       "    Whether to presort the data to speed up the finding of best splits in\n",
       "    fitting. For the default settings of a decision tree on large\n",
       "    datasets, setting this to true may slow down the training process.\n",
       "    When using either a smaller dataset or a restricted depth, this may\n",
       "    speed up the training.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "classes_ : array of shape = [n_classes] or a list of such arrays\n",
       "    The classes labels (single output problem),\n",
       "    or a list of arrays of class labels (multi-output problem).\n",
       "\n",
       "feature_importances_ : array of shape = [n_features]\n",
       "    The feature importances. The higher, the more important the\n",
       "    feature. The importance of a feature is computed as the (normalized)\n",
       "    total reduction of the criterion brought by that feature.  It is also\n",
       "    known as the Gini importance [4]_.\n",
       "\n",
       "max_features_ : int,\n",
       "    The inferred value of max_features.\n",
       "\n",
       "n_classes_ : int or list\n",
       "    The number of classes (for single output problems),\n",
       "    or a list containing the number of classes for each\n",
       "    output (for multi-output problems).\n",
       "\n",
       "n_features_ : int\n",
       "    The number of features when ``fit`` is performed.\n",
       "\n",
       "n_outputs_ : int\n",
       "    The number of outputs when ``fit`` is performed.\n",
       "\n",
       "tree_ : Tree object\n",
       "    The underlying Tree object.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The default values for the parameters controlling the size of the trees\n",
       "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
       "unpruned trees which can potentially be very large on some data sets. To\n",
       "reduce memory consumption, the complexity and size of the trees should be\n",
       "controlled by setting those parameter values.\n",
       "\n",
       "The features are always randomly permuted at each split. Therefore,\n",
       "the best found split may vary, even with the same training data and\n",
       "``max_features=n_features``, if the improvement of the criterion is\n",
       "identical for several splits enumerated during the search of the best\n",
       "split. To obtain a deterministic behaviour during fitting,\n",
       "``random_state`` has to be fixed.\n",
       "\n",
       "See also\n",
       "--------\n",
       "DecisionTreeRegressor\n",
       "\n",
       "References\n",
       "----------\n",
       "\n",
       ".. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
       "\n",
       ".. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
       "       and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
       "\n",
       ".. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
       "       Learning\", Springer, 2009.\n",
       "\n",
       ".. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
       "       http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.datasets import load_iris\n",
       ">>> from sklearn.model_selection import cross_val_score\n",
       ">>> from sklearn.tree import DecisionTreeClassifier\n",
       ">>> clf = DecisionTreeClassifier(random_state=0)\n",
       ">>> iris = load_iris()\n",
       ">>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
       "...                             # doctest: +SKIP\n",
       "...\n",
       "array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
       "        0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
